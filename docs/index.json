[{"content":"Introduction Resilio Sync is a file synchronization software that uses peer-to-peer (P2P) technology to share and sync files across devices. It enables secure, fast, and efficient file transfers by leveraging the BitTorrent protocol. Resilio Sync allows users to create shared folders or \u0026ldquo;syncs,\u0026rdquo; which are encrypted and accessible only to devices with the unique access key. Key features include real-time updates, no file size limits, cross-platform compatibility, and the ability to sync files without relying on cloud storage providers, ensuring privacy and control over data. It is commonly used for personal backups, team collaboration, and large-scale file distribution.\ncompose.yml services: resilio-sync: image: linuxserver/resilio-sync container_name: resilio-sync environment: - PUID=1000 - PGID=1000 - TZ=Asia/Manila volumes: - ./config:/config - ./downloads:/downloads ports: # - 8888:8888 # web GUI, to be proxied via caddy - 55555:55555 restart: unless-stopped networks: - caddynetwork networks: caddynetwork: external: true Notes Make sure to have already created the caddynetwork with docker network create caddynetwork Container port 8888 is proxied via caddy Change PUID, PGID, and TZ to what is applicable to your setup The first time you spin up the container and access the site, you will be prompted to create your username and password Caddyfile sync.deuts.org { reverse_proxy resilio-sync:8888 } ","permalink":"https://deuts.org/l/resilio-sync/","summary":"Resilio Sync is a peer-to-peer file synchronization tool that uses the BitTorrent protocol to securely and efficiently sync files across devices. It provides real-time updates, cross-platform support, and privacy-focused data transfer without relying on cloud storage.","title":"Resilio Sync"},{"content":"","permalink":"https://deuts.org/i/topics/","summary":"","title":"Topics"},{"content":"Technology today gives us the power to take full control—whether it’s self-hosting your own systems or automating tasks to simplify your life. Why rely on big tech when you can do it yourself? With the right mix of security and automation, you can build a digital fortress that keeps your data safe and your systems running smoothly. Think Docker containers and reverse proxies that keep everything in check, letting your tech run on autopilot. It\u0026rsquo;s all about making life easier, smarter, and more secure—with a bit of DIY flair.\nDeuts Log is all about exploring the world of technology and digital creativity. It’s a space to share ideas, knowledge, and personal projects, covering everything from data analysis to web development and beyond.\nThe blog’s journey started on Tumblr, where it built a small but passionate community. But as the need for more flexibility and performance grew, Deuts Log evolved. It was rebuilt using Hugo, a platform that supports speed and adaptability, reflecting the blog’s dedication to continuous improvement.\nAt its heart, Deuts Log is driven by curiosity and the pursuit of knowledge. Whether it’s diving deep into technical topics or discussing wider trends, the goal is to inspire learning and innovation—one post, one idea, one discovery at a time.\n","permalink":"https://deuts.org/i/about/","summary":"\u003cp\u003eTechnology today gives us the power to take full control—whether it’s \u003cstrong\u003eself-hosting\u003c/strong\u003e your own systems or automating tasks to simplify your life. Why rely on big tech when you can do it yourself? With the right mix of \u003cstrong\u003esecurity\u003c/strong\u003e and \u003cstrong\u003eautomation\u003c/strong\u003e, you can build a digital fortress that keeps your data safe and your systems running smoothly. Think \u003cstrong\u003eDocker\u003c/strong\u003e containers and \u003cstrong\u003ereverse proxies\u003c/strong\u003e that keep everything in check, letting your tech run on autopilot. It\u0026rsquo;s all about making life easier, smarter, and more secure—with a bit of \u003cstrong\u003eDIY\u003c/strong\u003e flair.\u003c/p\u003e","title":"About"},{"content":" Name Email Address Message ","permalink":"https://deuts.org/i/contact/","summary":"\u003cform id=\"fs-frm\" name=\"simple-contact-form\" accept-charset=\"utf-8\" action=\"https://formspree.io/f/xleyjlpp\" method=\"post\"\u003e\n  \u003cfieldset id=\"fs-frm-inputs\"\u003e\n    \u003clabel for=\"full-name\"\u003eName\u003c/label\u003e\n    \u003cinput type=\"text\" name=\"name\" id=\"name\" placeholder=\"Full Name\" required=\"\"\u003e\n    \u003clabel for=\"email-address\"\u003eEmail Address\u003c/label\u003e\n    \u003cinput type=\"email\" name=\"_replyto\" id=\"email-address\" placeholder=\"name@email.com\" required=\"\"\u003e\n    \u003clabel for=\"message\"\u003eMessage\u003c/label\u003e\n    \u003ctextarea rows=\"5\" name=\"message\" id=\"message\" placeholder=\"Describe your concerns here.\" required=\"\"\u003e\u003c/textarea\u003e\n    \u003cinput type=\"hidden\" name=\"_subject\" id=\"email-subject\" value=\"Contact Form Submission\"\u003e\n  \u003c/fieldset\u003e\n  \u003cinput type=\"submit\" value=\"Send\"\u003e\n  \u003ch3 id=\"my-form-status\"\u003e\u003c/h3\u003e\n\u003c/form\u003e\n\u003cscript\u003e\n  var form = document.getElementById(\"fs-frm\");\n  \n  async function handleSubmit(event) {\n    event.preventDefault();\n    var status = document.getElementById(\"my-form-status\");\n    var data = new FormData(event.target);\n    fetch(event.target.action, {\n      method: form.method,\n      body: data,\n      headers: {\n          'Accept': 'application/json'\n      }\n    }).then(response =\u003e {\n      if (response.ok) {\n        status.innerHTML = \"Your feedback has been received. Thank you!\";\n        form.reset()\n      } else {\n        response.json().then(data =\u003e {\n          if (Object.hasOwn(data, 'errors')) {\n            status.innerHTML = data[\"errors\"].map(error =\u003e error[\"message\"]).join(\", \")\n          } else {\n            status.innerHTML = \"Oops! There was a problem submitting your form\"\n          }\n        })\n      }\n    }).catch(error =\u003e {\n      status.innerHTML = \"Oops! There was a problem submitting your form\"\n    });\n  }\n  form.addEventListener(\"submit\", handleSubmit)\n\u003c/script\u003e\n\n\u003cstyle\u003e \n#fs-frm input,\n#fs-frm select,\n#fs-frm textarea,\n#fs-frm fieldset,\n#fs-frm optgroup,\n#fs-frm label,\n#fs-frm #card-element:disabled {\n  font-family: inherit;\n  font-size: 100%;\n  color: inherit;\n  border: none;\n  border-radius: 0;\n  display: block;\n  width: 100%;\n  padding: 0;\n  margin: 0;\n  -webkit-appearance: none;\n  -moz-appearance: none;\n}\n#fs-frm label,\n#fs-frm legend,\n#fs-frm ::placeholder {\n  font-size: .825rem;\n  margin-bottom: .5rem;\n  padding-top: .2rem;\n  display: flex;\n  align-items: baseline;\n}\n\n \n#fs-frm input,\n#fs-frm select,\n#fs-frm textarea,\n#fs-frm #card-element {\n  border: 1px solid rgba(0,0,0,0.2);\n  background-color: rgba(65, 65, 65, 0.9);\n  padding: .75em 1rem;\n  margin-bottom: 1.5rem;\n}\n#fs-frm input:focus,\n#fs-frm select:focus,\n#fs-frm textarea:focus {\n  background-color: #666;\n  outline-style: solid;\n  outline-width: thin;\n  outline-color: gray;\n  outline-offset: -1px;\n}\n#fs-frm [type=\"text\"],\n#fs-frm [type=\"email\"] {\n  width: 100%;\n}\n#fs-frm [type=\"button\"],\n#fs-frm [type=\"submit\"],\n#fs-frm [type=\"reset\"] {\n  width: auto;\n  cursor: pointer;\n  -webkit-appearance: button;\n  -moz-appearance: button;\n  appearance: button;\n}\n#fs-frm [type=\"button\"]:focus,\n#fs-frm [type=\"submit\"]:focus,\n#fs-frm [type=\"reset\"]:focus {\n  outline: none;\n}\n#fs-frm [type=\"submit\"],\n#fs-frm [type=\"reset\"] {\n  margin-bottom: 0;\n}\n\n#fs-frm [type=\"submit\"] {\n  background-color: #555;\n}\n\n#fs-frm [type=\"submit\"]:hover {\n  background-color: #999;\n}\n\n#fs-frm select {\n  text-transform: none;\n}\n\n#fs-frm [type=\"checkbox\"] {\n  -webkit-appearance: checkbox;\n  -moz-appearance: checkbox;\n  appearance: checkbox;\n  display: inline-block;\n  width: auto;\n  margin: 0 .5em 0 0 !important;\n}\n\n#fs-frm [type=\"radio\"] {\n  -webkit-appearance: radio;\n  -moz-appearance: radio;\n  appearance: radio;\n}\n\n \n#fs-frm fieldset.locale input[name=\"city\"],\n#fs-frm fieldset.locale select[name=\"state\"],\n#fs-frm fieldset.locale input[name=\"postal-code\"] {\n  display: inline;\n}\n#fs-frm fieldset.locale input[name=\"city\"] {\n  width: 52%;\n}\n#fs-frm fieldset.locale select[name=\"state\"],\n#fs-frm fieldset.locale input[name=\"postal-code\"] {\n  width: 20%;\n}\n#fs-frm fieldset.locale input[name=\"city\"],\n#fs-frm fieldset.locale select[name=\"state\"] {\n  margin-right: 3%;\n}\n\u003c/style\u003e","title":"Contact"},{"content":"Thinner hair vs. fat body, your choice #intermittentfasting www.hindustantimes.com/∞\n","permalink":"https://deuts.org/b/2024-12-17-11-07-3ldhuh6y7y22j/","summary":"\u003cp\u003eThinner hair vs. fat body, your choice \u003ca href=\"https://bsky.app/hashtag/intermittentfasting\"\u003e#intermittentfasting\u003c/a\u003e \u003ca href=\"https://www.hindustantimes.com/lifestyle/health/intermittent-fasting-for-weight-loss-study-reveals-shocking-side-effect-that-will-make-you-think-twice-101734150898530.html\"\u003ewww.hindustantimes.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ldhuh6y7y22j"},{"content":"GoToSocial, Misskey, Sharkey, Hollo, Iceshrimp, Pleroma, the list goes on. So which one is the best at being lightweight but feature complete?\n","permalink":"https://deuts.org/b/2024-12-17-00-19-3ldgqa25iis2s/","summary":"\u003cp\u003eGoToSocial, Misskey, Sharkey, Hollo, Iceshrimp, Pleroma, the list goes on. So which one is the best at being lightweight but feature complete?\u003c/p\u003e","title":"@deuts.hamili.net 3ldgqa25iis2s"},{"content":"Couldn\u0026rsquo;t really enjoy Jack + Coke when drinking alone.\n","permalink":"https://deuts.org/b/2024-12-17-00-02-3ldgpc6mhns2s/","summary":"\u003cp\u003eCouldn\u0026rsquo;t really enjoy Jack + Coke when drinking alone.\u003c/p\u003e","title":"@deuts.hamili.net 3ldgpc6mhns2s"},{"content":"A lot of #Mastodon users hating on #Bluesky, primarily because of its centralized nature. I wonder if these same users realize how much they are relying on their Mastodon instance administrotor (e.g. mastodon.social) instead of bsky.social.\n","permalink":"https://deuts.org/b/2024-12-16-21-28-3ldggnn2elc2s/","summary":"\u003cp\u003eA lot of \u003ca href=\"https://bsky.app/hashtag/mastodon\"\u003e#Mastodon\u003c/a\u003e users hating on \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e, primarily because of its centralized nature. I wonder if these same users realize how much they are relying on their Mastodon instance administrotor (e.g. mastodon.social) instead of bsky.social.\u003c/p\u003e","title":"@deuts.hamili.net 3ldggnn2elc2s"},{"content":"Jekyll themes like Just the Docs and Chirpy are some of the reasons why I would like to revisit my decision in the #Hugo vs. #Jekyll debate. deuts.org/∞ #GoHugo\n","permalink":"https://deuts.org/b/2024-12-16-17-57-3ldg2u5qzbc2g/","summary":"\u003cp\u003eJekyll themes like Just the Docs and Chirpy are some of the reasons why I would like to revisit my decision in the \u003ca href=\"https://bsky.app/hashtag/hugo\"\u003e#Hugo\u003c/a\u003e vs. \u003ca href=\"https://bsky.app/hashtag/jekyll\"\u003e#Jekyll\u003c/a\u003e debate. \u003ca href=\"https://deuts.org/p/hugo-vs-jekyll/\"\u003edeuts.org/∞\u003c/a\u003e \u003ca href=\"https://bsky.app/hashtag/gohugo\"\u003e#GoHugo\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ldg2u5qzbc2g"},{"content":"I’m torn between Bytestash and Opengist for my snippets repository. I love Opengist’s clean and simple design, but Bytestash’s robust search functionality is hard to overlook. github.com/∞ github.com/∞\n","permalink":"https://deuts.org/b/2024-12-16-17-54-3ldg2q4dntc2g/","summary":"\u003cp\u003eI’m torn between Bytestash and Opengist for my snippets repository. I love Opengist’s clean and simple design, but Bytestash’s robust search functionality is hard to overlook.\n\u003ca href=\"https://github.com/jordan-dalby/ByteStash\"\u003egithub.com/∞\u003c/a\u003e\n\u003ca href=\"https://github.com/thomiceli/opengist\"\u003egithub.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ldg2q4dntc2g"},{"content":"I don’t see much point in self-hosting PortChecker if it\u0026rsquo;s just for checking port status, which you can do on the official website anyway. Unless you’re set on hosting everything, it feels unnecessary! www.youtube.com/∞\n","permalink":"https://deuts.org/b/2024-12-16-17-52-3ldg2mfdy4s2g/","summary":"\u003cp\u003eI don’t see much point in self-hosting PortChecker if it\u0026rsquo;s just for checking port status, which you can do on the official website anyway. Unless you’re set on hosting everything, it feels unnecessary! \u003ca href=\"https://www.youtube.com/watch?v=0EgbXY0ZaeU\"\u003ewww.youtube.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ldg2mfdy4s2g"},{"content":"Explore the differences between Linkding and Hoarder, two popular bookmark management tools. Learn about their features, resource usage, and unique offerings to find the best fit for your needs. deuts.org/∞\n","permalink":"https://deuts.org/b/2024-12-16-17-34-3ldfzm5nsys2g/","summary":"\u003cp\u003eExplore the differences between Linkding and Hoarder, two popular bookmark management tools. Learn about their features, resource usage, and unique offerings to find the best fit for your needs. \u003ca href=\"https://deuts.org/p/linkding-vs-hoarder/\"\u003edeuts.org/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ldfzm5nsys2g"},{"content":"Linkding and Hoarder are two bookmark management tools with distinct strengths. Here\u0026rsquo;s a comparison of their features, resource usage, and other key details to help you choose the one that best meets your needs.\nContainer Images and Resource Usages Metric Linkding Hoarder-web Hoarder-chrome Hoarder-meilisearch Total for Hoarder Image Size 473 MB 823 MB 673 MB 147 MB 1.6 GB CPU Usage 0.11% 0.37% 0.03% 0.10% 0.50% Memory Usage 248.3 MiB 272.2 MiB 74.6 MiB 212.1 MiB 558.9 MiB Key Feature Differences Feature Linkding Hoarder AI Capabilities None available Can generate summaries and tags for bookmarks. Interface Design Sleek, with a blog-like feel for organizing bookmarks. Straightforward and functional. Public Bookmark Sharing Shared bookmarks can be made public, but the process could be smoother. No way to share bookmarks publicly. Subscribe to RSS feed None I can set up Hoarder to actually subscribe to the RSS feed of my Linkding instance Conclusion Linkding is a lightweight and efficient option with a minimalist design, while Hoarder offers advanced features like AI-generated tags but requires more system resources. The choice between the two comes down to whether you value simplicity and lower resource usage or extra functionality.\nWishlist for Linkding Feature Details Enhanced Public Bookmark Sharing Allow shared bookmarks to appear directly at the base URL. Adding an option to mark bookmarks as \u0026ldquo;public\u0026rdquo; instead of \u0026ldquo;shared\u0026rdquo;. Customization Options Enable users to change the site title and icon for a more personalized experience. ","permalink":"https://deuts.org/p/linkding-vs-hoarder/","summary":"A comparison of 2 bookmarking tools, focusing on their features, customization options, resource usage, and overall usability. Check out the highlights what makes each tool stand out.","title":"Linkding vs. Hoarder"},{"content":"I\u0026rsquo;m contemplating whether I should get an Apple TV or not. Any compelling reason why I should do so? I already have Google Chromecast with Google TV and Onn 4K. The Onn device is so buggy I though I could use an Apple TV in its stead.\n","permalink":"https://deuts.org/b/2024-12-16-10-27-3ldfbpagp7s2s/","summary":"\u003cp\u003eI\u0026rsquo;m contemplating whether I should get an Apple TV or not. Any compelling reason why I should do so? I already have Google Chromecast with Google TV and Onn 4K. The Onn device is so buggy I though I could use an Apple TV in its stead.\u003c/p\u003e","title":"@deuts.hamili.net 3ldfbpagp7s2s"},{"content":"Not, so bad, right? #VPSDeals\nBlack friday 2024 vps.4\nSelf-Managed 2vCPU 4GB RAM 1 IPv4 addresses 40GB SSD Storage 1TB Bandwidth Virtualizor - Start, stop, re-install your VPS $55.95 / 3 years\n","permalink":"https://deuts.org/b/2024-12-15-21-55-3lddxokrecs2j/","summary":"\u003cp\u003eNot, so bad, right? \u003ca href=\"https://bsky.app/hashtag/vpsdeals\"\u003e#VPSDeals\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eBlack friday 2024 vps.4\u003c/p\u003e\n\u003cp\u003eSelf-Managed\n2vCPU\n4GB RAM\n1 IPv4 addresses\n40GB SSD Storage\n1TB Bandwidth\nVirtualizor - Start, stop, re-install your VPS\n$55.95 / 3 years\u003c/p\u003e","title":"@deuts.hamili.net 3lddxokrecs2j"},{"content":"Am I the only one downloading media (movies and TV shows) for #Plex or #Jellyfin at only 720p in 2024?\n","permalink":"https://deuts.org/b/2024-12-15-21-16-3lddvjqge4k2r/","summary":"\u003cp\u003eAm I the only one downloading media (movies and TV shows) for \u003ca href=\"https://bsky.app/hashtag/plex\"\u003e#Plex\u003c/a\u003e or \u003ca href=\"https://bsky.app/hashtag/jellyfin\"\u003e#Jellyfin\u003c/a\u003e at only 720p in 2024?\u003c/p\u003e","title":"@deuts.hamili.net 3lddvjqge4k2r"},{"content":"I wonder how to enable openssh on @linuxserver.io Code Server #Docker image? docs.linuxserver.io/∞\n","permalink":"https://deuts.org/b/2024-12-15-15-28-3lddc3cqe7c2r/","summary":"\u003cp\u003eI wonder how to enable openssh on \u003ca href=\"https://bsky.app/profile/linuxserver.io\"\u003e@linuxserver.io\u003c/a\u003e Code Server \u003ca href=\"https://bsky.app/hashtag/docker\"\u003e#Docker\u003c/a\u003e image? \u003ca href=\"https://docs.linuxserver.io/images/docker-code-server/\"\u003edocs.linuxserver.io/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3lddc3cqe7c2r"},{"content":"Tududi - A Minimalist, Open-Source Task and Project Management Tool github.com/∞\nMy wish for this is a notification for overdue tasks via Gotify, Telegram or email.\n","permalink":"https://deuts.org/b/2024-12-15-15-10-3lddb2k5mas2r/","summary":"\u003cp\u003eTududi - A Minimalist, Open-Source Task and Project Management Tool \u003ca href=\"https://github.com/chrisvel/tududi\"\u003egithub.com/∞\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMy wish for this is a notification for overdue tasks via Gotify, Telegram or email.\u003c/p\u003e","title":"@deuts.hamili.net 3lddb2k5mas2r"},{"content":"Look at what I found: paste crap, get truth.\nwww.bullshitremover.com www.bullshitremover.com/∞\n","permalink":"https://deuts.org/b/2024-12-14-09-56-3lda72ic4os2w/","summary":"\u003cp\u003eLook at what I found: paste crap, get truth.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bullshitremover.com\"\u003ewww.bullshitremover.com\u003c/a\u003e\n\u003ca href=\"https://www.bullshitremover.com/\"\u003ewww.bullshitremover.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3lda72ic4os2w"},{"content":"For me I\u0026rsquo;m waiting around here for #Bluesky and #ATProto to mature and excited to try out all the cool features to come in the future, especially for those who have their own PDS instance like me.\n","permalink":"https://deuts.org/b/2024-12-14-09-35-3lda5uolrak2w/","summary":"\u003cp\u003eFor me I\u0026rsquo;m waiting around here for \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e and \u003ca href=\"https://bsky.app/hashtag/atproto\"\u003e#ATProto\u003c/a\u003e to mature and excited to try out all the cool features to come in the future, especially for those who have their own PDS instance like me.\u003c/p\u003e","title":"@deuts.hamili.net 3lda5uolrak2w"},{"content":"Why does it always have to be #Mastodon vs. #Bluesky? They can co-exist, you and your friends can sign up to both.\n","permalink":"https://deuts.org/b/2024-12-14-09-24-3lda5bcbgck2w/","summary":"\u003cp\u003eWhy does it always have to be \u003ca href=\"https://bsky.app/hashtag/mastodon\"\u003e#Mastodon\u003c/a\u003e vs. \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e? They can co-exist, you and your friends can sign up to both.\u003c/p\u003e","title":"@deuts.hamili.net 3lda5bcbgck2w"},{"content":"The chess world champions list. Of course missing in this list are Khalifman, Ponomariov, Khasimdzhanov, and Topalov. That\u0026rsquo;s how chaotic the chess world has been in the 90\u0026rsquo;s to 2000\u0026rsquo;s.\n","permalink":"https://deuts.org/b/2024-12-14-00-33-3ld77mskf6c2x/","summary":"\u003cp\u003eThe chess world champions list. Of course missing in this list are Khalifman, Ponomariov, Khasimdzhanov, and Topalov. That\u0026rsquo;s how chaotic the chess world has been in the 90\u0026rsquo;s to 2000\u0026rsquo;s.\u003c/p\u003e","title":"@deuts.hamili.net 3ld77mskf6c2x"},{"content":"I\u0026rsquo;ll bet this won\u0026rsquo;t take a year before it\u0026rsquo;ll be back to retirement. PLDT relaunching the Smart Money e-wallet despite having Maya www.abs-cbn.com/∞\n","permalink":"https://deuts.org/b/2024-12-14-00-06-3ld764fw4fc2d/","summary":"\u003cp\u003eI\u0026rsquo;ll bet this won\u0026rsquo;t take a year before it\u0026rsquo;ll be back to retirement.\nPLDT relaunching the Smart Money e-wallet despite having Maya\n\u003ca href=\"https://www.abs-cbn.com/news/business/2024/12/13/is-pldt-relaunching-smart-money-despite-having-maya-1655\"\u003ewww.abs-cbn.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld764fw4fc2d"},{"content":"Mind you, I already have a piece about this, why Bitcoin is a scam deuts.org/∞\n","permalink":"https://deuts.org/b/2024-12-13-23-43-3ld74sccdhc2d/","summary":"\u003cp\u003eMind you, I already have a piece about this, why Bitcoin is a scam \u003ca href=\"https://deuts.org/p/why-bitcoin-is-a-scam/\"\u003edeuts.org/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld74sccdhc2d"},{"content":"Story-telling time: Defending open source, protecting the future of WordPress automattic.com/∞\n","permalink":"https://deuts.org/b/2024-12-13-23-35-3ld74f4eiuc2d/","summary":"\u003cp\u003eStory-telling time: Defending open source, protecting the future of WordPress \u003ca href=\"https://automattic.com/protecting-wordpress/\"\u003eautomattic.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld74f4eiuc2d"},{"content":"This is the current size of my #Hugo build: 366 pages, 10 static file, done in 404ms. I wonder if there are any much bigger site, and how long did it take for you to build the site?\n","permalink":"https://deuts.org/b/2024-12-13-17-19-3ld6hdudxmk2d/","summary":"\u003cp\u003eThis is the current size of my \u003ca href=\"https://bsky.app/hashtag/hugo\"\u003e#Hugo\u003c/a\u003e build: 366 pages, 10 static file, done in 404ms. I wonder if there are any much bigger site, and how long did it take for you to build the site?\u003c/p\u003e","title":"@deuts.hamili.net 3ld6hdudxmk2d"},{"content":"Someone please help creating a custom #Bluesky feed. I have a #Selfhosting background, so if it\u0026rsquo;s something I can self-host, that\u0026rsquo;s better.\n","permalink":"https://deuts.org/b/2024-12-13-16-35-3ld6euljwe22i/","summary":"\u003cp\u003eSomeone please help creating a custom \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e feed. I have a \u003ca href=\"https://bsky.app/hashtag/selfhosting\"\u003e#Selfhosting\u003c/a\u003e background, so if it\u0026rsquo;s something I can self-host, that\u0026rsquo;s better.\u003c/p\u003e","title":"@deuts.hamili.net 3ld6euljwe22i"},{"content":"How to Add a Bluesky (bsky.app) Share Link to Hugo (PaperMod) ryomayama.com/∞ #Hugo #PaperMod #Bluesky\n","permalink":"https://deuts.org/b/2024-12-13-11-54-3ld5v6szrys2z/","summary":"\u003cp\u003eHow to Add a Bluesky (bsky.app) Share Link to Hugo (PaperMod) \u003ca href=\"https://ryomayama.com/en/2024/12/12/adding-bluesky-share-link-to-hugo-papermod/\"\u003eryomayama.com/∞\u003c/a\u003e \u003ca href=\"https://bsky.app/hashtag/hugo\"\u003e#Hugo\u003c/a\u003e \u003ca href=\"https://bsky.app/hashtag/papermod\"\u003e#PaperMod\u003c/a\u003e \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld5v6szrys2z"},{"content":"Finally was able to pull my #Bluesky posts into my #Hugo blog at deuts.org/bsky/ deuts.org/∞\n","permalink":"https://deuts.org/b/2024-12-13-11-25-3ld5tkbiik22c/","summary":"\u003cp\u003eFinally was able to pull my \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e posts into my \u003ca href=\"https://bsky.app/hashtag/hugo\"\u003e#Hugo\u003c/a\u003e blog at deuts.org/bsky/\n\u003ca href=\"https://deuts.org/bsky/\"\u003edeuts.org/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld5tkbiik22c"},{"content":"Saving this for later: Integrate Bluesky replies as your blog\u0026rsquo;s comment section in gohugo.io framework\n","permalink":"https://deuts.org/b/2024-12-13-09-16-3ld5mdjowrk2t/","summary":"\u003cp\u003eSaving this for later: Integrate Bluesky replies as your blog\u0026rsquo;s comment section in gohugo.io framework\u003c/p\u003e","title":"@deuts.hamili.net 3ld5mdjowrk2t"},{"content":"For my reference: Build options help define how Hugo must treat a given page when building the site. gohugo.io/∞\n","permalink":"https://deuts.org/b/2024-12-13-09-13-3ld5m6mhvmc2t/","summary":"\u003cp\u003eFor my reference: Build options help define how Hugo must treat a given page when building the site. \u003ca href=\"https://gohugo.io/content-management/build-options/\"\u003egohugo.io/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld5m6mhvmc2t"},{"content":"How come no one seems to be reviewing this #Beelink SER5 Pro AMD Ryzen 7 Pro 5850U #MiniPC? Google returns only online shops. Is this really a thing? Looks beefy for its price, though, albeit just DDR4 RAM at 3200MHz only.\necommerce.datablitz.com.ph/∞\n","permalink":"https://deuts.org/b/2024-12-12-21-21-3ld4eg2lxek2k/","summary":"\u003cp\u003eHow come no one seems to be reviewing this \u003ca href=\"https://bsky.app/hashtag/beelink\"\u003e#Beelink\u003c/a\u003e SER5 Pro AMD Ryzen 7 Pro 5850U \u003ca href=\"https://bsky.app/hashtag/minipc\"\u003e#MiniPC\u003c/a\u003e? Google returns only online shops. Is this really a thing? Looks beefy for its price, though, albeit just DDR4 RAM at 3200MHz only.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://ecommerce.datablitz.com.ph/products/beelink-ser5-pro-amd-ryzen-7-pro-5850u-processor-32gb-ram-1tb-ssd-windows-11-pro-mini-pc-black\"\u003eecommerce.datablitz.com.ph/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld4eg2lxek2k"},{"content":"I would have given @graysky.app a try but its lack for PDS support is a big deal breaker.\n","permalink":"https://deuts.org/b/2024-12-12-21-09-3ld4dqabs7s2k/","summary":"\u003cp\u003eI would have given \u003ca href=\"https://bsky.app/profile/graysky.app\"\u003e@graysky.app\u003c/a\u003e a try but its lack for PDS support is a big deal breaker.\u003c/p\u003e","title":"@deuts.hamili.net 3ld4dqabs7s2k"},{"content":"Can we have a list of World Champions with their headshots ala list of Presidents?\n","permalink":"https://deuts.org/b/2024-12-12-21-06-3ld4dkwkt7c2k/","summary":"\u003cp\u003eCan we have a list of World Champions with their headshots ala list of Presidents?\u003c/p\u003e","title":"@deuts.hamili.net 3ld4dkwkt7c2k"},{"content":"If I have #Bluesky PDS installed in a server using a domain name, can I still change the base domain name and retain my DID?\n@bsky.app\n","permalink":"https://deuts.org/b/2024-12-12-19-51-3ld47ercr622v/","summary":"\u003cp\u003eIf I have \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e PDS installed in a server using a domain name, can I still change the base domain name and retain my DID?\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://bsky.app/profile/bsky.app\"\u003e@bsky.app\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld47ercr622v"},{"content":"O no! We\u0026rsquo;re supposed to go home to Iloilo next week, and with a baby in tow. Should we cancel our flight?\n","permalink":"https://deuts.org/b/2024-12-12-18-46-3ld43qdyhoc25/","summary":"\u003cp\u003eO no! We\u0026rsquo;re supposed to go home to Iloilo next week, and with a baby in tow. Should we cancel our flight?\u003c/p\u003e","title":"@deuts.hamili.net 3ld43qdyhoc25"},{"content":"I wonder why I\u0026rsquo;m being logged out of my #Bluesky account here at openvibe app? Is it because I\u0026rsquo;m using an app password?\n","permalink":"https://deuts.org/b/2024-12-12-15-54-3ld3s4nvee22l/","summary":"\u003cp\u003eI wonder why I\u0026rsquo;m being logged out of my \u003ca href=\"https://bsky.app/hashtag/bluesky\"\u003e#Bluesky\u003c/a\u003e account here at openvibe app? Is it because I\u0026rsquo;m using an app password?\u003c/p\u003e","title":"@deuts.hamili.net 3ld3s4nvee22l"},{"content":"And the drama continues www.404media.co/∞\n","permalink":"https://deuts.org/b/2024-12-12-13-07-3ld3isl7vps2s/","summary":"\u003cp\u003eAnd the drama continues \u003ca href=\"https://www.404media.co/wordpress-wp-engine-preliminary-injunction/\"\u003ewww.404media.co/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld3isl7vps2s"},{"content":"No wonder why Wallabag on the Chrome Store is rated 3.7/5. It\u0026rsquo;s not working. chromewebstore.google.com/∞\n","permalink":"https://deuts.org/b/2024-12-12-10-13-3ld372joanc2n/","summary":"\u003cp\u003eNo wonder why Wallabag on the Chrome Store is rated 3.7/5. It\u0026rsquo;s not working.\n\u003ca href=\"https://chromewebstore.google.com/detail/wallabagger/gbmgphmejlcoihgedabhgjdkcahacjlj\"\u003echromewebstore.google.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3ld372joanc2n"},{"content":"I just read this post. Yes, it\u0026rsquo;s boringly simple PDS install. Good thing I got it on $11 per year VPS on Racknerd Black Friday deal.\n","permalink":"https://deuts.org/b/2024-12-12-10-05-3ld36n5nrjs2n/","summary":"\u003cp\u003eI just read this post. Yes, it\u0026rsquo;s boringly simple PDS install. Good thing I got it on $11 per year VPS on Racknerd Black Friday deal.\u003c/p\u003e","title":"@deuts.hamili.net 3ld36n5nrjs2n"},{"content":"I use ShareX, Notepad++, PowerToys, and Rufus from this list.\n","permalink":"https://deuts.org/b/2024-12-12-09-22-3ld34ans2cc2l/","summary":"\u003cp\u003eI use ShareX, Notepad++, PowerToys, and Rufus from this list.\u003c/p\u003e","title":"@deuts.hamili.net 3ld34ans2cc2l"},{"content":"Is there any Mastodon instance dedicated to chess players, hobbyists and fans? Would like to join one. Or, what if, I create one and convert chesshive.com to a Mastodon site?\n","permalink":"https://deuts.org/b/2024-12-12-00-10-3ld25ebq5ic2q/","summary":"\u003cp\u003eIs there any Mastodon instance dedicated to chess players, hobbyists and fans? Would like to join one. Or, what if, I create one and convert chesshive.com to a Mastodon site?\u003c/p\u003e","title":"@deuts.hamili.net 3ld25ebq5ic2q"},{"content":"It\u0026rsquo;s what we call crunchtime\n","permalink":"https://deuts.org/b/2024-12-11-23-21-3ld22mq5ec22q/","summary":"\u003cp\u003eIt\u0026rsquo;s what we call crunchtime\u003c/p\u003e","title":"@deuts.hamili.net 3ld22mq5ec22q"},{"content":"Is there any self-hosted web client for Bluesky (ATProto)? #selfhosting #selfhosted\n","permalink":"https://deuts.org/b/2024-12-11-19-22-3lczncynkbs2y/","summary":"\u003cp\u003eIs there any self-hosted web client for Bluesky (ATProto)?\n\u003ca href=\"https://bsky.app/hashtag/selfhosting\"\u003e#selfhosting\u003c/a\u003e \u003ca href=\"https://bsky.app/hashtag/selfhosted\"\u003e#selfhosted\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3lczncynkbs2y"},{"content":"When you install Tailscale on a Linux server and run the sudo tailscale up command, it automatically enables DNS management with the setting --accept-dns=true. This forces Tailscale to handle DNS resolution, which may not always be what you want.\nBy default, when you enable MagicDNS in the Tailscale admin panel, it overwrites your /etc/resolv.conf file with its DNS server 100.100.100.100. If you add a custom nameserver and enable Override local DNS, Tailscale will apply that DNS server across all devices in your Tailnet. This is useful if you’re using services like Pi-Hole or NextDNS.\nBut what if you want to disable Tailscale DNS on certain devices and revert to local DNS settings?\nDisabling Tailscale DNS on Linux To disable Tailscale\u0026rsquo;s DNS management on Linux, run:\nsudo tailscale set --accept-dns=false This command will revert your /etc/resolv.conf to the DNS values it had before Tailscale was installed, like 1.1.1.1 or 8.8.8.8. Your Linux server will no longer be affected by Tailscale\u0026rsquo;s DNS settings, which is useful if you prefer to manage DNS locally, particularly on a VPS where misconfigurations, either in the DNS settings or the ACL, can be problematic.\nTailscale DNS on Windows On Windows, this process is easier, as there\u0026rsquo;s a simple checkbox to disable Tailscale DNS in the system tray preferences. This GUI option offers a more straightforward way to adjust DNS settings without needing terminal commands.\nConclusion Tailscale’s DNS management is convenient, but sometimes you may need to regain control over DNS settings. Disabling Tailscale DNS on Linux is a quick way to ensure your server uses local DNS settings, keeping your configuration simple and reliable.\n","permalink":"https://deuts.org/p/tailscale-accept-dns-settings/","summary":"Learn how to disable Tailscale’s DNS settings on Linux and revert to local DNS configurations using a simple command.","title":"Tailscale Accept DNS Settings"},{"content":" Self Hosting a Bluesky PDS Alongside Other Services Setting up a Bluesky PDS to use a top-level domain, faced some configuration challenges, and documented the solutions to help others.\nLooking at this post, installing Bluesky PDS alongside your existing Docker containers feels like trying to solve a Rubik’s Cube blindfolded—tedious, complicated, and begging for trouble. One day, I hope someone delivers a streamlined setup, Linuxserver-style. Until then, it\u0026rsquo;s more like Bluesky DIY Edition.\n","permalink":"https://deuts.org/x/bluesky-pds-docker-dilemma/","summary":"Hosting Bluesky PDS with Docker is a tangled mess. Streamlined setups, where art thou?","title":"Bluesky PDS: Docker Dilemma"},{"content":"The Wallabag Chrome Extension feels about as useful as a bookmark on a broken page. Despite providing the correct client ID, client token, username, and password, it steadfastly refuses to work. It’s like yelling at a locked door with the key in hand.\nWallabag, if you’re listening, please fix this! Otherwise, I might just give Readeck a spin—and who knows, it might read me better than you do.\n","permalink":"https://deuts.org/x/wallabagged-extension-in-distress/","summary":"The Wallabag Chrome Extension is frustratingly broken when it comes to authentication.","title":"Wallabagged: Extension in Distress"},{"content":"Nah, nevermind. I think it was a matter of ACL. Wasn\u0026rsquo;t able to adjust ACL after my Pi-Hole IP address changed.\n","permalink":"https://deuts.org/b/2024-12-11-11-36-3lcytbc7ljs2k/","summary":"\u003cp\u003eNah, nevermind. I think it was a matter of ACL. Wasn\u0026rsquo;t able to adjust ACL after my Pi-Hole IP address changed.\u003c/p\u003e","title":"@deuts.hamili.net 3lcytbc7ljs2k"},{"content":"The Bluesky PDS server can go well with Tailscale in the same system, provided that you don\u0026rsquo;t use the Tailscale MagicDNS, by running sudo tailscale set --accept-dns=false\n","permalink":"https://deuts.org/b/2024-12-11-11-23-3lcysjnmpic2k/","summary":"\u003cp\u003eThe Bluesky PDS server can go well with Tailscale in the same system, provided that you don\u0026rsquo;t use the Tailscale MagicDNS, by running \u003ccode\u003esudo tailscale set --accept-dns=false\u003c/code\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3lcysjnmpic2k"},{"content":"It appears the PDS doesn\u0026rsquo;t go well with Tailscale.\n","permalink":"https://deuts.org/b/2024-12-11-11-02-3lcyre36duk2h/","summary":"\u003cp\u003eIt appears the PDS doesn\u0026rsquo;t go well with Tailscale.\u003c/p\u003e","title":"@deuts.hamili.net 3lcyre36duk2h"},{"content":"Two days in, and my Github issues on PDFDing remains unanswered: github.com/∞\n","permalink":"https://deuts.org/b/2024-12-10-23-18-3lcxjzlqxas2c/","summary":"\u003cp\u003eTwo days in, and my Github issues on PDFDing remains unanswered: \u003ca href=\"https://github.com/mrmn2/PdfDing/issues/26\"\u003egithub.com/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3lcxjzlqxas2c"},{"content":"This just goes to show how much of a mess it is maintaining a #Mastodon instance. Relays? FakeRelays? Sideqik? Not that I\u0026rsquo;m discouraging anyone, but be sure to allot time for these stuff: blog.thms.uk/∞\n","permalink":"https://deuts.org/b/2024-12-10-23-13-3lcxjq6gojc2p/","summary":"\u003cp\u003eThis just goes to show how much of a mess it is maintaining a \u003ca href=\"https://bsky.app/hashtag/mastodon\"\u003e#Mastodon\u003c/a\u003e instance. Relays? FakeRelays? Sideqik? Not that I\u0026rsquo;m discouraging anyone, but be sure to allot time for these stuff: \u003ca href=\"https://blog.thms.uk/2023/01/setting-up-mastodon\"\u003eblog.thms.uk/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3lcxjq6gojc2p"},{"content":"The Wallabag Chrome Extension is so useless, I can\u0026rsquo;t obtain the token from my instance. Provided the correct client ID, client token, username and password, but it just won\u0026rsquo;t push through.\n","permalink":"https://deuts.org/b/2024-12-10-22-11-3lcxgc7k4ss2p/","summary":"\u003cp\u003eThe Wallabag Chrome Extension is so useless, I can\u0026rsquo;t obtain the token from my instance. Provided the correct client ID, client token, username and password, but it just won\u0026rsquo;t push through.\u003c/p\u003e","title":"@deuts.hamili.net 3lcxgc7k4ss2p"},{"content":"Looking at this post, installing Bluesky PDS alongside other Docker containers you might already have existing in your system, looks tedious and complicated, and prone to issues. Someday, i hope to see a more streamline setup ala Linuxserver.\ncprimozic.net/∞\n","permalink":"https://deuts.org/b/2024-12-10-21-49-3lcxf2owgyk2p/","summary":"\u003cp\u003eLooking at this post, installing Bluesky PDS alongside other Docker containers you might already have existing in your system, looks tedious and complicated, and prone to issues. Someday, i hope to see a more streamline setup ala Linuxserver.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://cprimozic.net/notes/posts/notes-on-self-hosting-bluesky-pds-alongside-other-services/\"\u003ecprimozic.net/∞\u003c/a\u003e\u003c/p\u003e","title":"@deuts.hamili.net 3lcxf2owgyk2p"},{"content":"@deuts.fosstodon.org.ap.brid.gy o you\u0026rsquo;re here. And you\u0026rsquo;re me.\n","permalink":"https://deuts.org/b/2024-12-10-18-38-3lcx2e5jii22z/","summary":"\u003cp\u003e\u003ca href=\"https://bsky.app/profile/deuts.fosstodon.org.ap.brid.gy\"\u003e@deuts.fosstodon.org.ap.brid.gy\u003c/a\u003e o you\u0026rsquo;re here. And you\u0026rsquo;re me.\u003c/p\u003e","title":"@deuts.hamili.net 3lcx2e5jii22z"},{"content":"How do I freaking make my Bluesky PDS send verification email? I can\u0026rsquo;t seem to properly setup Resend for this! Help please!\n","permalink":"https://deuts.org/b/2024-12-10-16-59-3lcwuu25z2k2q/","summary":"\u003cp\u003eHow do I freaking make my Bluesky PDS send verification email? I can\u0026rsquo;t seem to properly setup Resend for this! Help please!\u003c/p\u003e","title":"@deuts.hamili.net 3lcwuu25z2k2q"},{"content":"Fire drill at TWC\n","permalink":"https://deuts.org/b/2024-12-10-15-25-3lcwplwyy7s2b/","summary":"\u003cp\u003eFire drill at TWC\u003c/p\u003e","title":"@deuts.hamili.net 3lcwplwyy7s2b"},{"content":"Running up some python codes on ChatGPT made me hit the free tier limits so fast.\n","permalink":"https://deuts.org/b/2024-12-10-12-49-3lcwgupds2k2y/","summary":"\u003cp\u003eRunning up some python codes on ChatGPT made me hit the free tier limits so fast.\u003c/p\u003e","title":"@deuts.hamili.net 3lcwgupds2k2y"},{"content":"Bluetooth speakers used to come with built-in microphones, like the JBL Go 1, making them perfect for online meetings and calls. But starting with newer models like the JBL Go 3, manufacturers have dropped this feature—and it’s frustrating. Why might this be happening?\nOne reason could be cost-cutting. Adding a microphone requires extra hardware and software like noise cancellation, which might not be worth the expense for manufacturers if most users aren’t using it. It’s also possible that companies want to simplify their devices, focusing on sound quality and portability instead of trying to make them all-purpose tools.\nAnother possibility is that manufacturers don’t want Bluetooth speakers to overlap with other products like smart speakers or earbuds, which are better suited for calls. Removing the mic helps clearly position Bluetooth speakers as music devices and avoids complaints about call quality or compatibility issues.\nBut for people like me, this design shift creates a real problem. If you use a mobile device like an Android phone or tablet for online meetings, a Bluetooth speaker without a mic is practically useless. You can’t separate the audio and mic functions, meaning you’re forced to either use the phone’s built-in speaker or switch to headphones. This limitation doesn’t exist on laptops, where you can mix and match input and output devices more freely.\nThe result? A once-convenient feature is gone, making Bluetooth speakers less versatile. While manufacturers might have their reasons, it feels like a step backward for users who relied on this functionality.\n","permalink":"https://deuts.org/p/bluetooth-speaker-built-in-mic/","summary":"Bluetooth speaker makers are removing built-in microphones, frustrating users who rely on them for online meetings. Possible reasons include cost-cutting, market positioning, and underutilization, with significant impacts on mobile users.","title":"Why Are Bluetooth Speakers Losing Their Built-In Microphones?"},{"content":"I\u0026rsquo;m wishing I could host my own Mastodon instance, but setting it up with Docker is unnecessarily complicated. There are countless dependencies to handle, multiple services to configure, and numerous potential points of failure. For a platform of its size, you\u0026rsquo;d expect a more straightforward, user-friendly Docker setup, but it\u0026rsquo;s anything but. Why is this process so difficult to get right?\n","permalink":"https://deuts.org/x/running-mastodon-via-docker-complicated/","summary":"A rant about the convoluted process of setting up Mastodon using Docker and the frustration of dealing with multiple dependencies and configurations.","title":"Why is Running Mastodon via Docker So Complicated?"},{"content":"I’ve been running Paperless NGX as my document management tool for a while now, but lately, I’ve started wondering if a simpler solution like PDFDing might be better suited for my needs. Both tools have their strengths and weaknesses, so I’ve been testing them side by side to see how they compare.\nPaperless NGX: Great Features, but Too Much? Paperless NGX has a lot going for it:\nOrganizes \u0026amp; Tags Documents: Scan and categorize documents with custom tags, correspondents, types, and more for easy retrieval. OCR \u0026amp; Multi-Language Support: Performs OCR on scanned documents, making them searchable. Supports over 100 languages via the Tesseract engine. Local Data Storage \u0026amp; Security: Your data is stored securely on your own server, with no transmission or sharing of your files. PDF/A Format for Long-Term Storage: Documents are saved in PDF/A format, designed for long-term storage, alongside the original files. Machine Learning for Metadata: Automatically tags documents with correspondents and document types, streamlining organization. Supports Multiple File Types: Supports PDFs, images, Office documents (Word, Excel, PowerPoint), and more. Modern Web Interface: Features a customizable dashboard, filtering options, drag-and-drop uploads, and customizable views. It also supports custom fields and shareable public links. Powerful Search \u0026amp; Auto-Suggestions: Full-text search, autocomplete, relevance-based sorting, and document highlighting make finding files efficient. Email Processing: Import and process documents directly from email accounts with customizable rules for actions such as marking as read or deleting. Consume Folder: Automatically processes documents dropped into a designated folder, making it easy to quickly add documents to the system without manual uploads. Multi-User Permissions \u0026amp; Workflow: A robust permissions system, with global and per-document access control, and a powerful workflow system for advanced management. Optimized for Performance: Utilizes multi-core systems for parallel document processing and includes an integrated sanity checker to ensure document archive health. However, these features come with some drawbacks:\nHigh Memory Usage: Paperless NGX uses about 1.4 GB of memory even when it’s idle. On a system with 11 GB of RAM, this is noticeable. Machine Learning Accuracy: Predictions are inconsistent. Correspondent and document type are about 50% accurate, and creation date predictions are wrong 80% of the time. Custom Fields: While you can create custom fields, they don’t appear by default and need to be enabled manually for every new document. Editing Limitations: Updating metadata for multiple documents is cumbersome since each document must be opened individually. A grid-style interface, similar to Airtable or spreadsheet apps, for faster and more efficient bulk editing would have been much better. PDFDing: Simple, Lightweight, and Efficient PDFDing takes a minimalist approach, using tags instead of multiple metadata fields. Its design is sleek and straightforward, similar to tools like Linkding, which I already use and appreciate.\nOne of the biggest advantages of PDFDing is how light it is on system resources. It uses only about 156 MB of memory on average, a fraction of what Paperless NGX demands.\nAdditionally, a standout feature of PDFDing is its ease of use on both desktop and mobile devices. When opening a document in the web app on a mobile browser, it’s displayed directly in the browser without triggering a download. This saves storage space and avoids cluttering your downloads folder with duplicate files if you repeatedly access the same document. In contrast, Paperless NGX downloads the file each time it’s viewed in full-page mode on mobile browsers, which can quickly become messy.\nWhat’s Missing in PDFDing Despite its simplicity, PDFDing isn’t perfect. The biggest feature I miss is Paperless NGX’s consume folder, which makes it easy to add and organize documents automatically. If PDFDing could implement this, it would make the decision to switch much easier.\nResource Usage Comparison To give some context, I’m running these tools on a system with 11 GB of RAM. Here’s how they compare in terms of system resource usage over the past week:\nPaperless NGX Container Name AveCPU AveMem (MiB) AveMem% paperless-webserver 7.10% 1155.12 10.53% paperless-tika 0.26% 277.51 2.53% paperless-gotenberg 0.06% 6.63 0.06% paperless-redis 0.39% 4.78 0.04% Total 7.81% 1444.05 13.17% PDFDing Container Name AveCPU AveMem (MiB) AveMem% pdfding 0.02% 156.36 1.43% Total 0.02% 156.36 1.43% Final Thoughts Right now, I’m undecided. Paperless NGX has powerful features but can feel over-engineered and resource-hungry. PDFDing is minimalist and efficient but lacks some key features I rely on.\nFor now, I’ll keep running both systems and see how PDFDing fits into my workflow. If it can streamline document management without too many compromises, it might be worth switching.\n","permalink":"https://deuts.org/p/switch-paperless-ngx-pdfding/","summary":"Paperless NGX is a feature-rich tool, but its complexity and resource usage have led me to explore simpler alternatives like PDFDing.","title":"Contemplating a Switch from Paperless NGX to PDFDing"},{"content":"The Philippine condo market is under scrutiny as rising prices, shrinking rental yields, and climbing vacancy rates raise red flags. The video below delves into these issues, highlighting the risks and potential pitfalls of investing in this challenging market.\n\u0026nbsp; I fully agree with the creator’s observations. Based on my personal experience and internal calculations, rental yields for new developments more likely fall below 3%, making renting significantly more affordable than buying. In areas like BGC, walking around at night reveals that many buildings appear under 20% occupied—perhaps even closer to 10%—judging by how few units are lit. This supports concerns about overbuilding and waning foreign demand. The absence of official vacancy rate data only adds to the market\u0026rsquo;s opacity.\nDespite these challenges, I see potential opportunities if a market correction occurs. Lower prices could present a chance to acquire properties at more reasonable values, whether for future living or long-term investment.\n","permalink":"https://deuts.org/p/ph-condo-market/","summary":"The Philippine condo market faces challenges such as low rental yields, high vacancy rates, and overvaluation. Could a correction be on the horizon?","title":"Is the Philippine Condo Market Overheating?"},{"content":"I used to enjoy window shopping on Lazada, particularly for Mini PCs. But lately, the experience has become tiresome, thanks to how vendors are allowed to list multiple specs—and even entirely different models—on a single product page.\nTake the Beelink SER5 Max Mini PC as an example. This model, powered by the AMD Ryzen 7 5800H processor, has been on my radar for a while. Typically, the 32GB RAM and 1TB NVMe storage variant sells for around Php22,000. But when you search for it on Lazada, you’ll encounter listings priced as low as Php7,995.\nSounds like a steal, right? Not so fast.\nWhen you click on the listing, you’ll find that the advertised price isn’t for the SER5 Max. Instead, it applies to an entirely different product—the Beelink S12 Pro with an N100 CPU, no RAM, and no storage. To make matters worse, these listings lump together multiple models, including the Beelink S12, SER3 3750H, SER5 5560U, and SER5 Max, each in varying configurations of RAM and storage.\nBy the time you navigate through the confusing options and finally select the SER5 Max with 32GB RAM and 1TB NVMe, the price is often much higher than expected—or the variant is not even available.\nThis approach makes it nearly impossible to distinguish real deals from regular prices. For shoppers like me, it’s a frustrating way to ruin sale events like 11.11, 12.12, or Black Friday.\nSuggestions for Lazada: Prohibit bundling completely different products/models under a single listing. It’s acceptable to group variants of the same model with differing RAM and storage, but combining entirely unrelated products should not be allowed. Introduce a mechanism that enables shoppers to report sellers who use deceptive listings to mislead customers and gain undue attention. By the way, this applies to Shopee as well. I\u0026rsquo;m just a loyal Lazada shopper (first-mover advantage), so my focus has been on Lazada so far.\n","permalink":"https://deuts.org/p/online-shopping-lazada/","summary":"Online shopping for Mini PCs on Lazada can be frustrating when misleading listings combine different products and specs under one page, making it harder to find real deals during sales.","title":"The Frustrations of Online Shopping on Lazada"},{"content":"I consider myself somewhere between intermediate and advanced in Power Query, but there\u0026rsquo;s always more to learn. One of the things I enjoy most is discovering new tricks to incorporate into my workflow.\nRecently, I watched the latest Power Query Tricks Battle video by Goodly on YouTube, featuring Melissa de Korte and Rick de Groot. It’s packed with creative techniques that can take your Power Query game to the next level.\nIt’s a shame Melissa’s mic quality wasn’t the best (perhaps she used a built-in laptop mic), but I’m confident her tricks were outstanding.\nWatch the video below and tell me if you learned something new, what tricks are you most excited about to try out in your projects, and which of the tricks featured is your favorite?\n\u0026nbsp; ","permalink":"https://deuts.org/p/new-power-query-tricks/","summary":"Explore new Power Query tricks from the latest Power Tricks Battle by Goodly. Learn something new and share your takeaways!","title":"Unlocking New Power Query Tricks"},{"content":" Hugo Admonitions Simple admonitions for hugo.\nNice design, blends well with dark themes. There are just too many options, though, that adds to the clutter.\nHints Hint shortcode can be used as hint/alerts/notification block. There are 3 colors to choose from: info, warning and danger.\nPart of the Hugo-Book theme, but we can take out the implementation and add the relevant css.\nCustomized callout boxes for Hugo What I look for in text is when it’s visually appealing. And I think callout boxes are a great way to direct the reader to important information. The Hugo Portio theme doesn’t ship with them, so I implemented and customized them. If you want something as nice as this, here’s your guide.\nThis is the current implementation, though I can\u0026rsquo;t promise it\u0026rsquo;ll be that way moving forward. It requires The Font Awesome font for the icons.\n","permalink":"https://deuts.org/x/admonitions-hints-callouts/","summary":"These are the available admonitions/hints/callouts implementation for your Hugo blog.","title":"Admonitions, Hints, or Callouts"},{"content":"Recently, a message was posted in Slicehosting\u0026rsquo;s Discord server that left many customers, including myself, in disbelief:\nDear [Customers/All],\nI regret to inform you that Slicehosting is now closed as I no longer have the time to manage it effectively. Refunds for any remaining subscription time have been issued and should appear in your bank accounts within 7 days.\nIf anyone is interested in taking over this project, I am open to offers for a reasonable price. Please feel free to contact me at support@slicehosting.tech for further details.\nThank you for your support, and I apologize for any inconvenience caused.\nBest regards,\nShivang Shastri\nThis announcement marked the abrupt end of a VPS provider that had appeared promising—at least at first glance.\nBack in September, I signed up for a Slicehosting VPS plan because they offered a deal that seemed too good to pass up. The service had even been mentioned on LowEndBox, lending it some credibility. However, as things turned out, Slicehosting has joined the ranks of fly-by-night VPS providers.\nHere’s the plan I got:\nPlan Details Description Value Price ($/yr) 12 CPU Core 2 Memory (GB) 4 Storage (GB, HDD) 20 My Experience While the plan looked appealing on paper, my time with Slicehosting was less than ideal. Here are some observations:\nFrequent Downtimes Before this week’s closure announcement, I encountered several instances of prolonged downtime, sometimes lasting multiple days. This made the service unreliable, even for non-critical tasks.\nUnderwhelming Performance The HDD storage was painfully slow. During performance tests, I compared the VPS’s storage to a directory mounted via rclone from OneDrive—and shockingly, the rclone-mounted directory outperformed the VPS’s local storage.\nRefunds: Wishful Thinking? In their message, Slicehosting mentioned issuing refunds for unused subscription time. While I remain hopeful, I can\u0026rsquo;t help but be skeptical given how chaotic things have been.\nFinal Thoughts Slicehosting’s closure is disappointing but not entirely surprising given the red flags many users observed over the past months. This experience underscores the importance of vetting VPS providers, especially when deals seem too good to be true.\nFor those affected, the promise of refunds offers a glimmer of hope, but only time will tell if Slicehosting follows through.\nIf you\u0026rsquo;re considering a budget VPS provider, learn from experiences like this: read reviews, test performance, and, when possible, pay monthly to avoid being stuck in situations like this.\n","permalink":"https://deuts.org/p/slicehosting-fly-by-night/","summary":"Slicehosting, a promising budget VPS provider, recently shut down, leaving users with reliability concerns and questions about refunds. Here’s my experience with their service and what it means for choosing budget VPS providers.","title":"The story of a fly-by-night VPS host"},{"content":"Enclosed is a minimalistic web application designed for sending private and secure notes.\nAll notes are end-to-end encrypted, ensuring that the server and storage have zero knowledge of the content. You can set a password, define an expiration period (TTL), and choose to have the note self-destruct after being read.\nA Promising Alternative to PrivateBin I’ve been using PrivateBin for secure note sharing, but its outdated interface often left me wishing for a modernized alternative. Enclosed, with its elegant default dark theme and minimalist design, feels like a breath of fresh air.\nWhile I haven’t completely switched yet, I’m seriously contemplating making Enclosed my primary tool. It addresses several pain points I had with PrivateBin, such as:\nA Modern, Elegant Interface: Enclosed stays true to its design philosophy, providing a clean and visually appealing experience. Improved Reliability: I often faced issues with PrivateBin where pastes would disappear after upgrades. I’m optimistic that Enclosed won’t suffer from the same problem, given its well-thought-out implementation. Features That Won Me Over Two recent updates in the last month to Enclosed particularly impressed me:\nRestricting Note Creation to Logged-In Users: This feature adds an extra layer of control, making the platform more secure. No Expiration Option: Previously, expiration periods were limited to 1 hour, 1 day, 1 week, or 1 month. Now, I can set notes to never expire, which is perfect for more persistent needs. These enhancements show the developer’s commitment to refining the app and meeting user needs, making Enclosed a very attractive alternative.\nMy Wishlist for Enclosed While Enclosed has been a joy to use so far, there are a few features I’d love to see added:\nDeleting Shared Notes: As a logged-in user, I’d like the option to delete notes I’ve shared, provided I know the key. More Formatting Options: Just like PrivateBin allows formatting pastes as markdown, plaintext, or source code, I hope Enclosed adds similar options—and ideally, supports even more formats. Final Thoughts Enclosed isn’t just a potential replacement for PrivateBin—it could become the best tool for secure note sharing. While I’m still evaluating it, the updates and overall experience have made a strong case for switching for good.\nIf you’re exploring alternatives for PrivateBin or looking for a secure, modern solution for note sharing, Enclosed is definitely worth a try.\n","permalink":"https://deuts.org/p/enclosed-privatebin-alternative/","summary":"Enclosed, with its sleek design and enhanced features, is a promising replacement for PrivateBin as a secure note-sharing app. Here’s why I’m considering making the switch.","title":"Enclosed could be the best PrivateBin replacement"},{"content":" PortChecker - Check for Open Ports EASILY Learn how to self-host portchecker.io using a Docker container! This handy tool allows you to check the port status of any hostname or IP address, which is essential for managing port forwarding and network security. In this video, we\u0026#39;ll walk you through the entire process, from downloading the Docker image to accessing your own private instance of portchecker.io.\nHonestly, I’m not sure why you\u0026rsquo;d bother self-hosting PortChecker—it\u0026rsquo;s just a tool to check your server\u0026rsquo;s port status. You can easily use the website for that. It’s not like it’s going to keep tabs on your ports 24/7, so unless you’re on a mission to host everything yourself, this might be a bit much!\n","permalink":"https://deuts.org/x/to-portchecker-or-not/","summary":"\u003cdiv class=\"post-entry\"\u003e\n    \u003ca href=\"https://www.youtube.com/watch?v=0EgbXY0ZaeU\" target=\"_blank\" class=\"linkcard-wrapper\"\u003e\n      \u003cdiv class=\"linkcard-content\"\u003e\n        \u003ch3 class=\"linkcard-title\"\u003ePortChecker - Check for Open Ports EASILY\u003c/h3\u003e\n        \u003cp class=\"linkcard-description\"\u003eLearn how to self-host portchecker.io using a Docker container! This handy tool allows you to check the port status of any hostname or IP address, which is essential for managing port forwarding and network security.  In this video, we\u0026#39;ll walk you through the entire process, from downloading the Docker image to accessing your own private instance of portchecker.io.\u003c/p\u003e\n      \u003c/div\u003e\n    \u003c/a\u003e\n  \u003c/div\u003e\n  \n\u003cp\u003eHonestly, I’m not sure why you\u0026rsquo;d bother self-hosting \u003ca class=\"applink\" href=\"https://deuts.org/a/portchecker\" target=\"_blank\"\u003ePortChecker\u003c/a\u003e—it\u0026rsquo;s just a tool to check your server\u0026rsquo;s port status. You can easily use the \u003ca href=\"https://portchecker.io/\"\u003ewebsite\u003c/a\u003e for that. It’s not like it’s going to keep tabs on your ports 24/7, so unless you’re on a mission to host \u003cem\u003eeverything\u003c/em\u003e yourself, this might be a bit much!\u003c/p\u003e","title":"To Portchecker or not?"},{"content":" GFiber Prepaid 100 Mbps fiber plans launched Globe has launched GFiber Prepaid 100 Mbps plans designed for value-conscious users, offering flexible options like 7-day, 30-day, or yearly subscriptions without long-term contracts. With stable, low-latency connections ideal for 4K streaming, gaming, and large file transfers, these plans balance affordability and performance for diverse needs.\nIf Globe can consistently deliver 50 Mbps, it would easily cover most of my everyday needs. After all, whether it’s streaming in HD, handling work tasks, or indulging in a bit of online gaming, reliable speed beats sheer numbers any day.\n","permalink":"https://deuts.org/x/gfiber-prepaid-100-mbps/","summary":"If Globe consistently delivers 50 Mbps, it would more than meet my daily needs, proving that reliability often outshines raw speed.","title":"GFiber Prepaid 100 Mbps"},{"content":" GCash faces another bank transfer glitch Just days after users reported unauthorized deductions from their accounts, popular e-wallet platform GCash faced another issue. On Friday afternoon, the Ayala-backed company announced that its bank transfer feature via BancNet was experiencing problems, though the cause was unclear.\nI guess I joined the unlucky club, as I was a victim of this GCash bank transfer glitch yesterday. The silver lining? My funds were credited to my GCash account today, after a 24-hour wait. Talk about an extended transfer \u0026ldquo;experience\u0026rdquo;!\nTo learn more about other people\u0026rsquo;s frustrating experiences about GCash, visit r/GCashIssues.\n","permalink":"https://deuts.org/x/gcash-bank-transfer-issues/","summary":"GCash\u0026rsquo;s BancNet transfer feature faces issues, leaving users waiting for transactions.","title":"GCash Bank Transfer Issues"},{"content":"I\u0026rsquo;m torn between Bytestash and Opengist for my snippets repository. I love Opengist\u0026rsquo;s clean and simple design, but Bytestash\u0026rsquo;s robust search functionality is hard to overlook.\n","permalink":"https://deuts.org/x/snippets/","summary":"\u003cp\u003eI\u0026rsquo;m torn between \u003ca href=\"https://github.com/jordan-dalby/ByteStash\"\u003eBytestash\u003c/a\u003e and \u003ca href=\"https://github.com/thomiceli/opengist\"\u003eOpengist\u003c/a\u003e for my snippets repository. I love Opengist\u0026rsquo;s clean and simple design, but Bytestash\u0026rsquo;s robust search functionality is hard to overlook.\u003c/p\u003e","title":"Snippets"},{"content":"Jekyll themes like Just the Docs and Chirpy are some of the reasons why I would like to revisit my decision in the Hugo vs. Jekyll debate.\n","permalink":"https://deuts.org/x/jekyll-themes/","summary":"\u003cp\u003eJekyll themes like \u003ca href=\"https://github.com/just-the-docs/just-the-docs\"\u003eJust the Docs\u003c/a\u003e and \u003ca href=\"https://github.com/cotes2020/jekyll-theme-chirpy\"\u003eChirpy\u003c/a\u003e are some of the reasons why I would like to revisit my decision in the \u003ca class=\"applink\" href=\"https://deuts.org/a/hugo\" target=\"_blank\"\u003eHugo\u003c/a\u003e vs. \u003ca class=\"applink\" href=\"https://deuts.org/a/jekyll\" target=\"_blank\"\u003eJekyll\u003c/a\u003e \u003ca href=\"https://deuts.org/p/hugo-vs-jekyll/\"\u003edebate\u003c/a\u003e.\u003c/p\u003e","title":"Jekyll Themes"},{"content":"If you\u0026rsquo;re deciding between Hugo and Jekyll for your static site generator, here\u0026rsquo;s a clear comparison to help you choose the right tool for your needs.\nCriteria Hugo Jekyll Performance Extremely fast; can rebuild thousands of pages in seconds. Great for large or frequently updated sites. Slower compared to Hugo, especially with large sites. Suitable for smaller, less frequently updated sites. Installation Simple: a single binary with no dependencies. Requires Ruby and Gems, which can be complex for non-Ruby users. Themes Flexible with advanced customization options and shortcodes. Templates use Go’s templating engine. Large library of pre-built themes. Uses Liquid templates, which are simpler but less powerful for advanced users. Markdown Support Native support with configurable front matter (TOML, YAML, JSON). Excellent for multilingual sites. Markdown support via plugins like kramdown. Front matter is YAML-only. Limited multilingual capabilities. Ecosystem Rapidly growing community with a smaller but expanding theme library. Hugo also has more GitHub stars, reflecting its developer appeal. Established ecosystem with a mature community and wide adoption. Native integration with GitHub Pages. Plugins No plugins; functionality is built-in or handled externally. Faster and more secure as a result. Extensive plugin ecosystem for advanced features. Can slow down build times and add complexity. Use Case Best for performance-focused, large, multilingual, or highly customized sites. Great for smaller sites, blogs, or projects requiring GitHub Pages integration or extensive plugins. On Github Pages Hosting\rJekyll has native support on GitHub Pages, allowing you to upload Markdown files directly to your repository and have the site built automatically on GitHub’s servers. In contrast, Hugo requires you to build the site yourself (using the hugo command) before deploying the generated static files to GitHub Pages. Recommendations Choose Hugo if you:\nNeed blazing-fast performance. Prefer a simpler installation process. Work on multilingual or large sites. Want flexibility and control over site structure and layout. Choose Jekyll if you:\nNeed an extensive plugin ecosystem. Want simplicity with pre-built themes. Rely heavily on GitHub Pages for hosting. Conclusion Hugo and Jekyll are both excellent tools, but your choice will depend on your specific needs. While Hugo\u0026rsquo;s rising GitHub star count highlights its developer-first focus and popularity among performance-conscious users, Jekyll shines with its ease of use and extensive theme community.\nAt the end of the day, Hugo and Jekyll are like coffee and tea—both get the job done, but one’s probably better suited to your taste. So, pick your brew, and let the static site-building begin!\n","permalink":"https://deuts.org/p/hugo-vs-jekyll/","summary":"A detailed comparison of Hugo and Jekyll, two popular static site generators, highlighting their performance, ease of setup, theme options, and hosting capabilities.","title":"Hugo vs. Jekyll: Which One Should You Choose?"},{"content":"Introduction When working with GitHub repositories, it\u0026rsquo;s common to use SSH keys to authenticate instead of passwords. However, if you\u0026rsquo;re managing multiple repositories or working on a single repository with specific security needs, you might want to configure SSH keys for just one repository. In this guide, we’ll walk you through setting up a dedicated SSH key to securely sync with a single GitHub repository, improving security, especially when storing private keys on remote servers or VPS.\nWhy Use SSH Keys for a Specific Repository? Using a single SSH key for a repository restricts access to only that repository. This isolation is useful in several scenarios:\nImproved security: If your private key is compromised, access is limited to just the target repository. Granular control: You can control which key has access to which repository, making it easier to manage multiple keys for different tasks. Simplified automation: When using deploy keys or automation scripts, this approach can be used to grant access to only one repository at a time. Step 1: Generate a New SSH Key If you don’t already have a specific SSH key for your GitHub repository, start by generating one. You can use ssh-keygen to create a new key pair.\nssh-keygen -t ed25519 -C \u0026#34;your_email@example.com\u0026#34; -f ~/.ssh/github_repo_id_ed25519 This will create two files:\n~/.ssh/github_repo_id_ed25519 (your private key) ~/.ssh/github_repo_id_ed25519.pub (your public key) The private key should never be shared or exposed, while the public key will be added to your GitHub repository.\nStep 2: Add the Public Key to Your GitHub Repository Go to your GitHub repository, and in the Settings section, add the public key as a deploy key:\nNavigate to Settings → Deploy Keys. Click Add deploy key. Give it a name (e.g., \u0026ldquo;GitHub SSH Key\u0026rdquo;). Paste the contents of your github_repo_id_ed25519.pub file into the key field. Select either read-only or read-write access depending on the level of access you want. Click Add key to save.\nStep 3: Configure SSH for the Repository Now, configure SSH to use the specific key for accessing the repository. You can do this by adding an entry to your ~/.ssh/config file.\nnano ~/.ssh/config Add the following configuration, replacing github-repo with your preferred alias and ensuring the path to your private key is correct:\nHost github-repo HostName github.com User git IdentityFile ~/.ssh/github_repo_id_ed25519 IdentitiesOnly yes This configuration tells SSH to use the specific key github_repo_id_ed25519 when connecting to GitHub.\nStep 4: Update or Add the Remote URL in Your Local Repository Sync a local repository To sync your local repository with the GitHub repository, change the remote URL to use the SSH alias you’ve configured in ~/.ssh/config. Navigate to your local Git repository and run the following:\ncd /path/to/your/repository git remote set-url origin git@github-repo:username/repository.git Make sure to replace username/repository.git with the actual repository path.\nAdd remote repository to local To add a remote repository:\ncd /path/to/your/repository git init git remote add origin git@github-repo:username/repository.git Step 5: Test the SSH Connection Now that everything is set up, verify that your SSH connection works properly by running:\nssh -T github-repo You should see a message like:\nHi username! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. This confirms that the SSH key is correctly configured and is being used to authenticate with GitHub.\nStep 6: Push Changes to GitHub Once the remote URL is updated, you can start syncing your local repository with GitHub. To push changes to your GitHub repository, simply run:\ngit push origin main # Or the relevant branch name Git will use the SSH key associated with the github-repo alias to authenticate and push your changes.\nConclusion By following these steps, you’ve securely configured SSH to access a specific GitHub repository. This approach not only enhances security by limiting access but also provides better management of your SSH keys, especially when dealing with multiple repositories or automating workflows.\nWith this setup, you can now safely push, pull, and manage your GitHub repository without the risk of exposing your other repositories or credentials.\n","permalink":"https://deuts.org/p/ssh-key-github-repo/","summary":"Secure your GitHub repo with SSH keys! This guide shows you how to limit access to just one repository, perfect for keeping your private keys safe on remote servers or VPS.","title":"How to Use an SSH Key for a Specific GitHub Repository"},{"content":"Understanding Hugo’s Section Structure Hugo organizes content into sections based on directories that contain an _index.md file. This file acts as the homepage for the section and controls how content is displayed. Here\u0026rsquo;s how sections and subsections behave:\nSections in Hugo Parent Section (_index.md):\nA folder with an _index.md file defines a section. Hugo lists the content from this section, including content from any subsections (directories with their own _index.md files). Subsection (Subfolder with _index.md):\nA subfolder with its own _index.md file defines a subsection. The content from this subsection’s _index.md will appear as part of the parent section’s content. Example Structure content/staging ├── _index.md # Section 1 (Homepage) ├── new-post/index.md └── sample ├── _index.md # Section 2 (Homepage) ├── check.md └── post.md Section 1: Lists new-post/index.md and includes content from sample/_index.md (Section 2), displaying it as part of Section 1. Section 2: Lists content files check.md and post.md as part of its own content. Key Takeaways Parent sections list and display content from their subsections, including the content from the _index.md of the subsections. Subsections list their own content (like check.md, post.md) but not the content from the parent section. ","permalink":"https://deuts.org/p/understanding-hugo-sections-index/","summary":"Learn how Hugo organizes content into sections using \u003ccode\u003e_index.md\u003c/code\u003e files, and how parent sections display content from their subsections.","title":"Understanding Hugo’s Section Structure with `_index.md` Files"},{"content":"Why This Guide Matters If you’re like me, you might have struggled to find a clear guide to setting up Picsur with ShareX . Picsur boasts some excellent features, including ShareX integration, but documentation for this feature is practically non-existent.\nThe official Picsur GitHub repository and its website lack instructions. GitHub issues on this topic were closed without providing clear answers. No help could be found in popular forums like r/selfhosted. To save you the same frustration, here’s a detailed step-by-step guide to integrate Picsur with ShareX.\nStep 1: Generate an API Key in Picsur Log in to your Picsur instance. Navigate to the Api Keys page from the settings menu. Click Generate API Key, and give it a descriptive name, like ShareX API. Save your changes. Step 2: Configure the ShareX Integration In the settings menu of Picsur, go to the ShareX page (located next to Api Keys). From the dropdown, select the API key you just created. Set the Image Format to PNG (recommended for high-quality uploads). Click the Export Config button to download the .sxcu file. Step 3: Import the Config to ShareX Locate the downloaded .sxcu file on your system. Double-click the file to open it. You’ll see a prompt asking if you want to set Picsur as the active custom uploader for ShareX. Confirm by clicking Yes. Tip for automatic upload\rTo automatically upload images to your Picsur instance, configure ShareX's After capture tasks and enable the Upload image to host option. Happy Screenshotting! Once setup is complete, you can use ShareX to take screenshots and have them automatically uploaded to your Picsur instance. This setup ensures quick, reliable, and self-hosted screenshot management.\n","permalink":"https://deuts.org/p/picsur-sharex-setup/","summary":"Struggling to set up Picsur with ShareX? This guide walks you through the entire process, from generating an API key in Picsur to configuring ShareX as your custom uploader.","title":"How to Set Up Picsur with ShareX for Seamless Screenshot Uploading"},{"content":"When setting up Docker containers, choosing the one with minimal setup can significantly affect the overall performance, complexity, and maintenance requirements of your services. For many use cases, especially when I’m the sole user of the system, I find that SQLite is the perfect database choice. Here\u0026rsquo;s why:\nMinimal Number of Containers – SQLite doesn’t require a separate database server, which keeps the setup minimal. Fewer containers mean less complexity, making the Docker environment easier to maintain and monitor. I’m the Only User Most of the Time – SQLite is embedded into the application, so there’s no need for complex client-server systems when I’m the only user. This makes it a perfect fit for small-scale, low-traffic use cases. Lightweight, Fast, and Easy to Set Up – SQLite is lightweight and fast, with no server to configure or maintain. The database is stored in a single file, making setup quick and Docker Compose files easier to manage. Reduced Maintenance and Overhead – Without the need for database clustering, replication, or scaling, SQLite simplifies maintenance. I only need to manage one file and ensure backups are in place. Portability and Flexibility – SQLite databases are stored as single files, so they can be easily moved, backed up, or transferred between environments without complex configurations or network dependencies. Less Network Overhead – Since SQLite runs locally, there’s no need for network communication, resulting in faster response times and reduced network overhead compared to client-server databases. Whenever I’m presented with multiple Docker services that serve the same purpose, or when an SQLite-only option is available, I usually prefer SQLite. Case in point: Why I chose Medama. It\u0026rsquo;s simple and fulfills my needs without the overhead of managing an additional database server, making it perfect for personal projects, prototypes, and low-traffic applications.\nI recognize that SQLite might not always be the best choice for every project, and I’m open to hearing differing perspectives. If you believe a dedicated database like MySQL, PostgreSQL, or another RDBMS is the better route, I’d love to hear why.\n","permalink":"https://deuts.org/p/why-sqlite-docker/","summary":"SQLite’s simplicity, minimal setup, and low maintenance make it an ideal choice for Docker services, especially when you\u0026rsquo;re the sole user. The highlights the reasons why SQLite works perfectly for small-scale personal applications.","title":"Why I Prefer SQLite-Only Docker Services"},{"content":"Black Friday is the de facto holiday for tech enthusiasts, and VPS hunters know it’s the golden hour to snag unbeatable deals. Case in point: RackNerd’s stunning Black Friday offer this year.\nFor just $18.93/year, here’s what you get:\n2 vCPU Cores 40 GB Pure SSD Storage 2.5 GB RAM 3000 GB Monthly Transfer 1 Gbps Network Port Full Root Admin Access 1 Dedicated IPv4 Address KVM / SolusVM Control Panel Multiple Locations to choose from! Compare that to RackNerd’s recent 11.11 sale for $17.98/year:\n1x vCPU Core 25 GB SSD Storage 2 GB RAM 3000GB Monthly Bandwidth 1Gbps Public Network Port Full Root Admin Access 1 Dedicated IPv4 Address KVM / SolusVM Multiple Locations Sure, the 11.11 sale shaves off $0.95, but for less than a dollar more on Black Friday, you get:\nDouble the vCPU cores 15 GB more SSD storage An extra 0.5 GB of RAM Of course, there are other options at varying hardware configurations and prices if you follow the links above.\nIf the 11.11 deal is a steal, then the Black Friday deal is straight-up daylight robbery—with a bigger bag to carry your spoils!\nYou\u0026#39;ve been warned!\rBlack Friday VPS deals are highly addictive! Proceed with caution, or better yet, hand your credit card to a responsible adult—preferably one without a tech obsession. 😉 If you’ve been holding out for a VPS upgrade, Black Friday is your cue. And deals like this? They’ll vanish faster than you can say \u0026ldquo;KVM-powered SSD.\u0026rdquo;\n","permalink":"https://deuts.org/p/black-friday-vps-deals/","summary":"Dive into the ultimate shopping season for tech enthusiasts—Black Friday. Here’s a comparison of RackNerd’s sizzling VPS deals this year versus their 11.11 sale.","title":"Black Friday VPS Deals: More Bang, Less Buck, and a Side of Virtual Glory"},{"content":"I was recently browsing through selfh.st looking for a Google Analytics alternative for my public websites. I wanted something that would give me the basic insights I need, without being bloated or overly complicated. After narrowing it down, I ended up considering three options: Umami, Matomo, and Medama.\nWhy I\u0026rsquo;m Moving Away from Google Analytics Before we jump into the alternatives, let me first explain why I’m steering clear of Google Analytics—because sometimes, less is more!\nSelf-Hosted Simplicity: Google Analytics, while powerful, requires an external service and complex integration. I prefer a self-hosted solution where I have full control over my data, without relying on third-party providers.\nGoogle Analytics is Hard to Navigate: I’ve always found Google Analytics difficult to navigate, especially when looking for specific insights. The overwhelming number of features and menus can make it hard to pinpoint exactly what I want without wading through unnecessary options.\nPrivacy Concerns: While it’s not always discussed openly, Google Analytics sometimes includes tracking scripts that could be seen as invasive. With data collection practices that tie into Google\u0026rsquo;s wider ecosystem, it could potentially compromise user privacy in ways that I don’t fully control. For example, data shared with Google can be used for advertising purposes, which might not align with my privacy policies.\nExcessive Complexity for Basic Needs: For most of my websites, I don\u0026rsquo;t need detailed reports or a high level of tracking. I just want to know which pages are visited, where my traffic is coming from, and what devices or browsers visitors are using. Google Analytics can do this, but it requires navigating through complex dashboards and reports that are too advanced for my simple needs.\nUmami: Great but Not Without Issues I’ve tried Umami before and had some issues with it. When I upgraded to a newer version, I encountered errors that disrupted my tracking. Additionally, Umami requires a separate database container, either MySQL or Postgres, which added complexity to my setup. For a simple analytics solution, it felt like a bit too much to maintain.\nMatomo: Too Bloated for My Needs Next up was Matomo, which was previously known as Piwik. I’ve used Matomo before, especially in environments like cPanel, but I found it to be too bloated for my use case. There are so many features, many of which I never use, that navigating through the platform often felt overwhelming. With countless options and pages to browse, it became difficult to figure out what was essential versus what was unnecessary. It’s powerful, but I just needed something much simpler.\nWhat I Really Want: Simple, Effective Analytics At this point, I realized that all I wanted was a simple tool that would tell me which pages on my website are popular, where my visitors are coming from, what devices and browsers they\u0026rsquo;re using, and the sources that brought them there. I didn’t need extensive reports or a full-blown dashboard with complex features. I wanted basic insights without the clutter.\nWhy I Chose Medama After further research, I finally settled on Medama, and here’s why:\nLightweight Tracker: Medama’s simplicity is its strength. It provides just the essentials and does it well. SQLite Database Support: Unlike Umami, Medama uses SQLite, which is easier to manage and doesn’t require setting up a separate database container. Simple and Intuitive Interface: The interface is clean and easy to navigate, making it much more user-friendly than the other options I explored. My Wish for Medama One feature I’d love to see in Medama is the ability to filter out my own browsing activity from the statistics. It would be great to ensure my personal visits to my website don’t skew the data.\nA Potential Jetpack Replacement? If my experience with Medama continues to be positive, I might even consider replacing Jetpack on my WordPress site. Jetpack Stats is really the only feature that keeps me using Jetpack, alongside Akismet for spam protection. If Medama proves to be a reliable and lightweight tracker, it could serve as an ideal replacement for my needs.\n","permalink":"https://deuts.org/p/medama-vs-google-analytics/","summary":"After testing Umami and Matomo, I’ve chosen Medama for its lightweight nature, ease of use, and SQLite database support. It’s a no-frills solution that gives me exactly what I need without the unnecessary complexities.","title":"Exploring Google Analytics Alternatives: Why I Chose Medama"},{"content":"A calendar table is an essential component of effective data modeling. It serves as a centralized hub for date-related calculations, enabling analysts to unlock powerful insights while maintaining a clean and organized model.\nPurpose of a Calendar Table Date-based Analysis: A calendar table allows for consistent time-based aggregations, such as year-to-date (YTD), quarter-over-quarter (QoQ), and month-over-month (MoM) comparisons. Handling Complex Calculations: Advanced calculations like working days, fiscal calendars, or custom holidays become easier with a well-structured calendar table. Seamless Filtering: Calendar tables provide a single source of truth for date filtering across related tables, ensuring accuracy. Improved Performance: Predefined relationships between the calendar and fact tables improve query performance and reduce the need for repeated calculations. Creating Calendar Table in Power Query In my Excel workflow, I encountered an unusual bug while generating a Calendar table with DAX, possibly related to differences in date formats (mm/dd/yyyy vs. dd/mm/yyyy). Because of this, I prefer using Power Query to create Calendar tables. If you feel the same way, here’s the code to generate a dynamic Calendar table:\nlet StartDate = #date(2022,1,1), EndDate = #date(2023,12,31), Source = List.Dates(StartDate,Duration.Days(EndDate-StartDate)+1,#duration(1,0,0,0)), ExpandDate = Table.TransformColumnTypes(Table.RenameColumns(Table.FromList(Source, Splitter.SplitByNothing(), null, null, ExtraValues.Error),{{\u0026#34;Column1\u0026#34;, \u0026#34;Date\u0026#34;}}),{{\u0026#34;Date\u0026#34;, type date}}), InsertYear = Table.AddColumn(ExpandDate, \u0026#34;Year\u0026#34;, each Date.Year([Date]), Int64.Type), InsertMonNum = Table.AddColumn(InsertYear, \u0026#34;MonNum\u0026#34;, each Date.Month([Date]), Int64.Type), InsertMonth = Table.AddColumn(InsertMonNum, \u0026#34;Month\u0026#34;, each Text.Start(Date.MonthName([Date]), 3), type text) in InsertMonth How to Use This Code: Paste it into Power Query’s Advanced Editor. Adjust the StartDate and EndDate to fit your needs. Load the table into your model. By incorporating a calendar table into your data model, you gain the ability to perform more advanced and precise analysis while streamlining your workflow. Whether you use DAX or Power Query, the results will elevate the power and efficiency of your reporting.\n","permalink":"https://deuts.org/p/power-query-calendar-table/","summary":"A calendar table is crucial for unlocking the full potential of your data model. Learn why it\u0026rsquo;s essential, common challenges with DAX, and how to quickly create one using Power Query with dynamic code you can customize.","title":"Power Query Calendar Table"},{"content":"When it comes to securing your applications, the choice often boils down to what best fits your needs and resources. After exploring my options, I decided that Cloudflare Access was the right tool for the job.\nThe Complexity of Authelia and Authentik Authelia and Authentik are robust tools for managing application security, but using them comes with several challenges:\nComplex Setup: Setting up either solution requires multiple Docker containers—typically three or four—for just a single instance. Server Overhead: Running these extra containers means higher resource consumption, which can strain your server and add unnecessary maintenance. Single Point of Failure: These systems act as gatekeepers for your applications. If they go down, so does access to all your apps—even simple, low-risk ones. This creates a dependency that adds unnecessary risk, especially for small-scale projects. Time Investment: Learning to configure and maintain these systems demands significant time and effort—something not always feasible for smaller projects. Why I Chose Cloudflare Access Rather than spending my time managing self-hosted tools like Authelia or Authentik, I turned to Cloudflare Access. Here’s what makes it stand out:\nCentralized Management: Cloudflare Access provides a unified dashboard to easily manage all your applications in one place. Straightforward Setup: There’s no need for additional containers or a complicated configuration process—just a few steps and you’re up and running. Domain-Level Implementation: Cloudflare Access is implemented directly at the domain or subdomain level, eliminating the need to spin up yet another Docker container to manage access. This makes it lightweight and efficient. Built-In Resilience: Unlike Authelia or Authentik, Cloudflare Access avoids creating a single point of failure. Cloudflare’s globally distributed infrastructure ensures that your applications remain available, even in the face of disruptions. Seamless Integration: It works smoothly with popular identity providers like Google Workspace and GitHub, simplifying authentication management. Zero Trust Security: Cloudflare Access includes powerful features like Zero Trust policies and device posture checks, ensuring only authorized users can access your applications. Bonus Benefits: Using Cloudflare Access means leveraging Cloudflare’s network for additional perks like DDoS protection and improved application performance. Why It Might Be Right for You If your goal is to simplify application security without sacrificing reliability, Cloudflare Access is an excellent choice. It eliminates the complexity of self-hosted solutions, reduces server overhead, and removes the risk of losing access due to a single point of failure.\n","permalink":"https://deuts.org/p/cloudflareaccess-vs-authelia-vs-authentik/","summary":"Authelia and Authentik are powerful tools for securing applications, but their complexity and inherent single points of failure make Cloudflare Access a better choice for me.","title":"I Choose Cloudflare Access over Authelia/Authentik"},{"content":"File synchronization tools are a cornerstone of my workflow, especially for keeping my Obsidian vaults updated across devices. For a while, Resilio Sync seemed like the perfect solution. But a recent issue has me questioning whether it’s as reliable as I believed.\nThe Issue: \u0026ldquo;No Tracker Connection Available\u0026rdquo; Just today, I encountered an unsettling error in Resilio Sync: \u0026ldquo;No tracker connection available.\u0026rdquo; After a quick search, I found a discussion in the Resilio Sync community confirming that others are facing the same issue.\nThis raised several concerns:\nDoes Resilio Sync rely on a single centralized tracker server? If so, is this a critical single point of failure? Can I continue trusting this service for my essential files? The more I thought about it, the more uneasy I became about relying solely on Resilio Sync.\nWhy This Is a Problem Reliability is critical for any file synchronization tool. My files—and particularly my Obsidian vaults—must remain accessible, no matter what. A centralized server outage undermines this reliability, potentially leaving me unable to sync files when I need them most.\nWhy I Chose Resilio Sync Over Syncthing I switched to Resilio Sync after experiencing some frustrations with Syncthing. Here’s why:\nMobile App Support:\nResilio Sync has a reliable Android app and an official iOS app (even though I’m not using iOS right now). Syncthing’s Android app has been discontinued, and there’s no official iOS app, which made Resilio Sync the better choice for cross-platform use. User-Friendly Interface:\nResilio Sync offers a polished GUI, whereas I found Syncthing’s login system problematic in the past. Selective Sync:\nThis feature is a game-changer for saving storage space on mobile devices and is unavailable in Syncthing. These factors made Resilio Sync seem like the ideal solution. But today’s issue makes me wonder if I prioritized convenience over long-term reliability.\nThe Bigger Picture: Can I Trust Resilio Sync? This experience highlights an important question: should I rethink my choice of file synchronization tool? While Resilio Sync offers valuable features, its potential reliance on a central tracker server feels like a vulnerability.\nI’m now left pondering:\nShould I revisit Syncthing, even with its app limitations and lack of selective sync? Are there other alternatives that balance reliability and functionality better? For now, I’ll be closely watching how quickly Resilio Sync resolves this issue. But one thing is certain: my trust in the platform has taken a hit.\nUpdate: Trackers Up Now After nearly 1.5 days, the trackers are finally back online. I wish Resilio Sync would provide an official announcement explaining the issue—it would go a long way in reassuring loyal users like me.\n","permalink":"https://deuts.org/p/resilio-sync-reliability-issues/","summary":"Resilio Sync has served me well, but recent tracker connection issues have raised questions about its reliability. Is it the best choice for syncing critical files?","title":"Did I Make a Mistake Trusting Resilio Sync for File Syncing?"},{"content":"Just when I thought I was done blogging about bad services, here I am again. I couldn\u0026rsquo;t resist letting this one out.\nIt\u0026rsquo;s been almost 3 days without internet at home in Salcedo Village, Makati. The provider? None other than the reliable PLDT.\nTheir initial response when I reported the issue? I was assigned a ticket stating restoration may take—wait for it—up to 36 hours. Not great, but manageable, right? Fast forward 72 hours (double the time promised), and what do I get? A message saying they\u0026rsquo;ll provide an update (not even a fix!) within another 48 hours.\nPLDT, it seems, has no sense of urgency to address the concerns of its paying customers. If you\u0026rsquo;re in the internet provider business, 1 day of downtime might be acceptable, but three days? That\u0026rsquo;s absurd.\nNow, thanks to PLDT’s stellar service, I’m forced to use my mobile hotspot for the weekend. What a bummer. I’ll be eating into my phone’s data provision just to get work done. Honestly, PLDT should be the one footing the bill for my backup internet.\nAnd let’s not forget their audacity to lock customers into 3-year contracts! I wish Converge had been available in my building when I was shopping for wired internet 10 months ago. At least I\u0026rsquo;d have a shot at better service.\nSo, PLDT service is actually this bad, huh? I always thought those horror stories were just urban myths—tales spun to scare unsuspecting subscribers. But nope, they’re real. And here I am, starring in my own PLDT nightmare.\nUpdate 11/17/2024 6:13am After 85 hours of downtime, my PLDT internet was finally back online.\n","permalink":"https://deuts.org/p/pldt-no-internet-downtime/","summary":"After almost 3 days without internet in Salcedo Village, Makati, PLDT\u0026rsquo;s service woes are proving to be more than just urban legends. From promises of a 36-hour restoration to endless delays, this is my frustrating experience with their \u0026lsquo;reliable\u0026rsquo; service.","title":"The PLDT Horror: 72 Hours (and Counting) Without Internet"},{"content":"Securing your web services with SSL/TLS certificates is crucial, especially when dealing with public servers. Using Caddy’s built-in HTTPS functionality is easy, but situations involving firewalls, CGNAT, or a lack of access to port 80/443 benefit from Cloudflare\u0026rsquo;s DNS challenge for seamless certificate automation. This tutorial outlines how to build a custom Caddy Docker image that integrates Cloudflare’s DNS module using xcaddy to streamline this process.\nWhy Opt for Cloudflare DNS Challenge? Caddy\u0026rsquo;s HTTP and TLS challenges work well for most, but the DNS challenge shines when:\nYour server is behind a firewall or CGNAT. You want to avoid exposing ports 80 and 443 to the public. Your setup includes a load balancer or other restrictive networking configurations. This method authenticates your domain ownership via the Cloudflare DNS API, allowing Caddy to fetch certificates without the need for open HTTP/HTTPS ports. See How the DNS Challenge Works for more info.\nBuilding a Custom Caddy Image The Dockerfile follows a multi-stage build:\nBuilder Stage: We use xcaddy to compile Caddy with the Cloudflare DNS provider plugin. Final Stage: The resulting binary is copied to a fresh Caddy image, creating a production-ready and lean container. How to Set Up and Run Step 1: Create a Custom Docker Network (Optional) Creating a custom Docker network keeps services isolated and minimizes the need to expose ports on your VPS:\ndocker network create caddynetwork If you choose a different network name, ensure the compose.yml file reflects it.\nStep 2: Create your compose.yml file Below is the compose.yml configuration, which builds a custom Caddy Docker image and sets up networking for enhanced security:\nservices: caddy: build: context: . dockerfile: Dockerfile container_name: caddy environment: - CLOUDFLARE_API_TOKEN=\u0026lt;ENTER YOUR TOKEN HERE\u0026gt; - CADDY_ACME_EMAIL=\u0026lt;ENTER YOUR EMAIL HERE\u0026gt; ports: - \u0026#34;80:80\u0026#34; - \u0026#34;443:443\u0026#34; volumes: - ./Caddyfile:/etc/caddy/Caddyfile - ./data:/data - ./config:/config restart: unless-stopped networks: - caddynetwork networks: caddynetwork: external: true Step 3: Configure compose.yml Rename _compose.yml to compose.yml and set your environment variables:\nenvironment: - CLOUDFLARE_API_TOKEN=\u0026lt;YOUR_TOKEN\u0026gt; - CADDY_ACME_EMAIL=\u0026lt;YOUR_EMAIL\u0026gt; CLOUDFLARE_API_TOKEN: Ensure this token has permissions for DNS zone edits on Cloudflare. CADDY_ACME_EMAIL: This email will be used by ACME for certificate registration. Step 4: Build and Run Use Docker Compose to build and start the container in detached mode:\ndocker compose up -d --build Step 5: Edit Your Caddyfile Adjust your Caddyfile with the necessary domain and service details. Here’s a sample:\nexample.com { reverse_proxy localhost:8080 tls { dns cloudflare {env.CLOUDFLARE_API_TOKEN} } } Replace example.com with your actual domain. Set localhost to the name or IP of your backend service. Adjust 8080 to the port where your application runs. With this setup, Caddy will use Cloudflare’s DNS challenge to obtain certificates, keeping your services secure without exposing common HTTP/HTTPS ports.\nHow the DNS Challenge Works Typically, to issue an SSL/TLS certificate, Caddy (or any Certificate Authority, CA) needs to verify that you actually own the domain in question. Normally, this is done by:\nHTTP Challenge: Verifying domain ownership by placing a file on an accessible web server running on port 80. TLS-ALPN Challenge: Verifying via a specific response from a server running on port 443. However, both these methods require public access to specific ports on the server (80 or 443), which may not be feasible if:\nYour server is behind a firewall or behind Carrier-Grade NAT (CGNAT) on a network that doesn’t expose external ports. You don’t want to expose ports 80 and 443 publicly for security or regulatory reasons. You’re using a load balancer or reverse proxy setup where ports may not map directly to a specific server. Why the Cloudflare DNS Challenge Solves This The DNS challenge verifies domain ownership by checking for specific DNS records instead of requiring public access to your server. Here’s how it works:\nCaddy uses Cloudflare’s API to add a special TXT record to your domain’s DNS settings (hosted on Cloudflare). The CA (e.g., Let’s Encrypt) queries Cloudflare’s DNS servers for the TXT record to verify domain ownership. Once verified, the CA issues a certificate to Caddy for your domain, which it saves and manages. Because the DNS challenge doesn’t involve your server’s IP address or port accessibility, it allows Caddy to obtain certificates even when direct access to your server is restricted.\nWhy You Need Cloudflare API Permissions The DNS challenge requires dynamically creating and removing DNS records on your domain during each certificate renewal. By providing Caddy with Cloudflare’s API token, you enable it to manage the necessary DNS records for verification, fully automating the certificate issuance and renewal process without exposing any ports.\nIn summary, the Cloudflare DNS challenge is essential when public port access is unavailable or undesirable. It’s a robust way to automate certificate management, especially in complex network environments, by verifying domain ownership through DNS rather than HTTP or TLS ports.\n","permalink":"https://deuts.org/p/caddy-docker-cloudflare-dns-challenge/","summary":"This guide provides a custom Dockerized Caddy image setup that uses Cloudflare DNS for SSL/TLS verification, ideal for servers behind firewalls or NAT.","title":"Custom Caddy Docker image with Cloudflare DNS challenge support"},{"content":"HTTP Basic Authentication offers a quick way to secure access to internal or staging services in a Docker environment, especially for controlled scenarios where high security isn’t critical. Although credentials sent via Basic Authentication can be decoded if intercepted, combining it with HTTPS ensures encryption, making it suitable for simple use cases. Here, we’ll set up Caddy as a reverse proxy with Basic Authentication to limit access to a service running in another container.\nScenario Overview In this example, we have:\nA Caddy container named caddy A service container named sampledockercontainer, which is the service we’re protecting, running on port 8080 Both containers are on the same Docker network The goal is to limit access to the sampledockercontainer service with Basic Authentication Setting Up the Caddyfile Start with a simple Caddyfile that proxies traffic to the sampledockercontainer:\nexample.com { reverse_proxy sampledockercontainer:8080 } This configuration forwards all requests for example.com to the sampledockercontainer service within the Docker network.\nGenerating a Hashed Password for Authentication Since Caddy is running as a Docker container, use the following docker exec command to generate a hashed password for authentication:\ndocker exec -it caddy caddy hash-password --plaintext \u0026#39;yoursupersecretpassword\u0026#39; Assuming your username is user, the command returns a hashed password like:\n$2a$14$UnmpufOS3hIBsW5Jn.lbpe0qtoa5kCKYfJNPGsgnOr2D6mPma8aPm Adding Basic Authentication to the Caddyfile Update the Caddyfile to include Basic Authentication, securing access to example.com:\nexample.com { basicauth { user $2a$14$UnmpufOS3hIBsW5Jn.lbpe0qtoa5kCKYfJNPGsgnOr2D6mPma8aPm } reverse_proxy sampledockercontainer:8080 } Now, visitors will be prompted for a username and password before gaining access.\nRestricting Authentication to Specific Paths You may want only certain paths to require authentication, allowing general access to others. For example, you can limit Basic Authentication to the /admin path while keeping the root URL publicly accessible:\nexample.com { basicauth /admin/* { user $2a$14$UnmpufOS3hIBsW5Jn.lbpe0qtoa5kCKYfJNPGsgnOr2D6mPma8aPm } reverse_proxy /admin/* sampledockercontainer:8080 reverse_proxy /* sampledockercontainer:8080 } With this setup:\nRequests to example.com are open to all users. Requests to example.com/admin/ require a valid username and password. Conclusion This Caddyfile setup demonstrates a simple, effective way to protect containerized services with Basic Authentication. For Dockerized applications, Caddy makes it easy to limit access to sensitive areas, securing your internal or staging environments with minimal configuration.\n","permalink":"https://deuts.org/p/docker-caddy-basic-auth/","summary":"Learn how to secure a Docker-hosted service with Caddy’s HTTP Basic Authentication, an effective way to protect access in controlled environments. This guide walks through configuring Caddy as a reverse proxy with Basic Authentication to limit access to a containerized service.","title":"Securing Your Docker-Hosted Service with HTTP Basic Authentication in Caddy"},{"content":"Why use callouts Callouts in notes or web content are a secret weapon for enhancing readability and guiding the reader’s focus. By spotlighting key points such as tips, warnings, or action items, callouts break up dense text, making it visually engaging and easy to navigate—perfect for readers who like to skim for the good stuff. Think of them as visual pitstops for key information.\nBeyond making content look better, callouts help readers retain critical details. By emphasizing important points, callouts make it more likely that the message will stick long after the reader has moved on. Plus, they boost engagement, encouraging readers to linger on essential details they might otherwise miss. In short, callouts don’t just share information; they make it memorable.\nHugo support for callouts Hugo doesn’t come with built-in support for callouts, but there’s a simple solution—shortcodes! By using a shortcode, you can add custom callouts to your Hugo content with ease.\nHugo shortcode for callouts Thanks to Cosimameyer’s tutorial on implementing callouts in Hugo, we can use the following example shortcodes:\nInfo {{\u003c callout type=\"info\" title=\"Information\" \u003e}}\rThis is an informational callout with default styling.\r{{\u003c /callout \u003e}} Information\rThis is an informational callout with default styling. Success {{\u003c callout type=\"success\" title=\"Success\" \u003e}}\rTell me more about your success story.\r{{\u003c /callout \u003e}} Success\rTell me more about your success story. Error {{\u003c callout type=\"error\" title=\"Mistake\" \u003e}}\rYou're making a big mistake!\r{{\u003c /callout \u003e}} Mistake\rYou're making a big mistake! Warning {{\u003c callout type=\"warning\" title=\"Caution\" \u003e}}\rYou have been warned!\r{{\u003c /callout \u003e}} Caution\rYou have been warned! Others {{\u003c callout type=\"nothing\" title=\"Nothing\" \u003e}}\rThis is nothing!\r{{\u003c /callout \u003e}} Nothing\rThis is nothing! ","permalink":"https://deuts.org/p/hugo-callouts/","summary":"Learn how to use callouts to improve readability and focus in your notes or web content. This post covers the importance of callouts, Hugo\u0026rsquo;s support for them, and how to implement custom callouts with shortcodes.","title":"Enhancing Readability with Callouts in Hugo"},{"content":"Recent controversies surrounding Matt Mullenweg and WP Engine have led me to rethink my blogging platform. While WordPress has long been a popular CMS, I’m increasingly drawn to the simplicity and control of static site generators like Hugo.\nWhy Consider Hugo Over WordPress? Hugo’s performance and security benefits are difficult to ignore:\nPerformance: Hugo serves static HTML files without any backend load, delivering high-speed access. Security: Without a database or PHP reliance, Hugo sites inherently avoid many vulnerabilities that affect WordPress. Customization: Total control over templates and layouts eliminates the plugin bloat that can slow down WordPress. Version Control: Working with Git keeps my changes organized and easy to revert if needed. Low Maintenance: No frequent updates or patches—Hugo just works as-is, saving time on upkeep. Despite these advantages, I hesitated because managing content directly in Hugo, especially from the terminal, felt clunky compared to the WordPress dashboard. Using VS Code helped, but it was still missing that CMS simplicity.\nMy New Workflow: Obsidian and Hugo with Minimal Dependencies I\u0026rsquo;ve now found a balance that works without tying me to specific plugins that may become obsolete or unsupported. Here’s what my current workflow looks like:\nObsidian with Templater and Dataview Plugins:\nI use Obsidian for creating and editing posts, keeping my Hugo directory aligned with my Obsidian vault. With Templater, I can build posts from templates and generate shortcodes. The Dataview plugin helps me get an overview of post summaries without impacting the publishing process. Notably, I’ve chosen not to use plugins like Hugo Publish or Static Site MD Exporter. Relying on such plugins could cause future complications if they’re discontinued, so I’ve kept my setup as independent as possible. Building with Hugo:\nAfter editing posts, I use Hugo to generate HTML files, configured to output to a docs folder for simplicity. Publishing to GitHub Pages:\nPushing my Hugo directory, including the docs folder, to GitHub triggers publishing through GitHub Pages. This approach enables a completely self-managed site without relying on an external CMS. If I don’t have Obsidian access, I can still edit content through GitHub’s web interface, pull the changes, run Hugo to build, and push the updated site back. Direct Edit Links:\nFor convenience, each site page includes a subtle edit button linking to the GitHub page source, making updates simple. Considering Migration While I’m currently set on Hugo for future posts, the complexity involved in migrating my WordPress content — nearly 900 posts and 2,500 comments — makes me pause. Migrating everything isn’t an easy task, so for now, I’m planning to blog on Hugo going forward while exploring efficient ways to gradually bring over my legacy content.\nThis workflow with Hugo, Obsidian and Github Pages has struck the right balance, letting me blog on my terms without depending on plugins or external services. Obsidian, Hugo, and GitHub all rely on Markdown, creating a seamless experience where these tools work in perfect harmony. For anyone seeking a lean, self-reliant approach to publishing, this setup might be the perfect fit.\n","permalink":"https://deuts.org/p/build-hugo-obsidian-github-pages-workflow/","summary":"Recent WordPress controversies have pushed me toward Hugo for blogging, drawn by its performance, security, and simplicity. My workflow with Obsidian and Hugo minimizes dependencies, offering a streamlined, self-hosted solution.","title":"Building an Efficient Blogging Workflow with Hugo, Obsidian, and GitHub Pages"},{"content":"When starting a new project, it\u0026rsquo;s best practice to initialize the Git repository with main as the default branch (instead of the usual master). This post will walk you through how to set up your local repository, link it to a GitHub repository, and push your changes, including the setup for authentication using GitHub’s Personal Access Token (PAT).\n1. Initialize a Git Repository with main as the Default Branch Begin by navigating to the directory where your project is located. Run the following commands to initialize Git with the main branch directly.\ncd /path/to/your/project git init --initial-branch=main 2. Stage and Commit Your Files Next, add all files to the staging area and commit them:\ngit add . git commit -m \u0026#34;Initial commit\u0026#34; 3. Link Your Local Repository to GitHub Now, set up a connection to your GitHub repository. Instead of using the default origin label for the remote, you can specify a custom label like github, which will allow flexibility with multiple remotes if needed.\ngit remote add github https://github.com/deuts/deuts.github.io.git 4. Push to GitHub without Using origin For the first push, use the -u flag to set github as the default remote:\ngit pull github main --rebase git push -u github main After this initial push, you can use git push and git pull directly without specifying the remote every time, as Git will use github by default for this branch.\n5. Authentication: When You\u0026rsquo;ll Need Your Email and Personal Access Token (PAT) When pushing to GitHub for the first time, Git will prompt you to set up authentication. Here’s what to expect:\nEmail: If this is the first time using Git on your machine, Git will ask you to set your email and name:\ngit config --global user.email \u0026#34;you@example.com\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34; This is required for all commits, as GitHub associates your email with your GitHub account.\nPersonal Access Token (PAT): Instead of your GitHub password, Git now requires a PAT for authentication. When prompted to log in, enter your username and the PAT as the password.\nTo create a PAT:\nGo to GitHub’s PAT settings. Generate a token with repo access. Use this token in place of your password when Git requests authentication. Common Commands Summary Initialize a Git repository with main: git init --initial-branch=main Add and commit changes: git add . git commit -m \u0026#34;Commit message\u0026#34; Add a custom remote (github) and push: git remote add github https://github.com/deuts/deuts.github.io.git git push -u github main Push and pull with defaults: git push # no need for origin git pull # no need for origin With this setup, you\u0026rsquo;ll be using the main branch, avoiding the default origin label, and ensuring secure access with GitHub’s Personal Access Token (PAT) system.\nWatch this video if you want for more context \u0026nbsp; ","permalink":"https://deuts.org/p/git-repository-to-github/","summary":"A guide on initializing a Git repository in Linux with main as the default branch and securely pushing to GitHub using a Personal Access Token (PAT), ideal for those looking to streamline their Git setup.","title":"Setting Up a Git Repository for Pushing to GitHub"},{"content":"When combining Obsidian with Hugo for a streamlined blogging workflow, several plugins claim to offer an easy publishing process, but some fall short due to misalignment with Hugo’s expectations. In this post, I’ll highlight some common issues with the plugins I’ve encountered.\nThe Problem with Available Obsidian Plugins Hugo Publish One plugin that attempts to bridge the gap between Obsidian and Hugo is Hugo Publish. This plugin lets you assign tags to notes, which it then processes into Markdown files that can be used with Hugo. However, there\u0026rsquo;s a significant flaw: if you assign a blog tag to your notes for processing, the plugin carries this tag over to the output .md files. This means that every post, when built with Hugo, will include the blog tag, which is not only redundant but goes against the purpose of using tags as categories or topics.\nThe problem here is that Hugo Publish does not account for the need to handle tags dynamically for each post. In Hugo, tags are often used for grouping and categorization, and repeating the same tag across all posts diminishes their value.\nStatic Site MD Exporter Another plugin, Static Site MD Exporter, offers a different approach by publishing the processed .md files directly to GitHub. From there, you can use git pull to bring them into your Hugo project and build the site.\nThis plugin offers a useful feature: by adding published: true in the frontmatter of a note, it marks the note for processing and publishing. However, this is where things start to break down when using Hugo. The published property is actually an alias for publishDate in Hugo, which expects a date value, not a boolean. As a result, when you run the hugo build command, Hugo throws an error because it cannot interpret published: true correctly.\nSummary Both the Hugo Publish and Static Site MD Exporter plugins offer valuable functionality, but they fall short in handling tags and frontmatter properties according to Hugo’s conventions. The inability of these plugins to properly manage publishDate and tags leads to errors when building the Hugo site and creates unnecessary redundancy in post tags. These are important issues that need to be addressed in order for the workflow to function smoothly with Hugo.\n","permalink":"https://deuts.org/p/hugo-and-obsidian-workflow/","summary":"A guide on how to use Obsidian in conjunction with Hugo for a streamlined blogging workflow, highlighting the issues with existing Obsidian plugins and their impact on Hugo builds.","title":"Hugo and Obsidian workflow"},{"content":"I\u0026rsquo;m just leaving this here for my future reference. This is the faster way to generate running total in Power Query.\n\u0026nbsp; Though, I think this next video has more useful code process:\n\u0026nbsp; ","permalink":"https://deuts.org/p/list-generate-running-total/","summary":"You want a more efficient way of generating running total in Power Query?","title":"Using List.Generate to Generate Running Total Column in Power Query"},{"content":"There is a 2-year old thread on Reddit. Many in the comments say it doesn\u0026rsquo;t make sense.\nI\u0026rsquo;ve successfully implemented Samba natively in the past. The problem with native implementation is that you can take note of the procedures you\u0026rsquo;ve made to make it running, but when you need to reinstall your Linux OS or install in another box, you have to go through all those procedures again. With Docker, especially if you already have a working docker compose file, you just need to back up and/or carry over that yml file to the new box.\nSo here are the resources I will need to revisit in the future for a Docker implementation of Samba:\nCrazy Max - docker compose file ServerContainers Samba - sample docker compose file ","permalink":"https://deuts.org/p/samba-on-docker/","summary":"Many say Samba on Docker doesn\u0026rsquo;t make sense. But does it?","title":"Samba Docker or Native"},{"content":"Browsing through Jim\u0026rsquo;s Garage on Youtube, and his Github repository, I was inspired to finally give these Docker apps a try:\nImmich Paperless-ngx Vikunja rClone Restic ","permalink":"https://deuts.org/p/my-docker-apps-to-install-in-2024/","summary":"This is a checklist of Docker apps I want to spin up and test in the near future.","title":"Docker Apps to Install"},{"content":"In August, I posted about my problems running Vikunja via Docker.\n\u0026nbsp; Based on the above video, however, there seems to be no more requirement in a Docker install of Vikunja for a separate API container?\nIs this a sign I should start using Vikunja now? Let\u0026rsquo;s see. As soon as I get the time.\nThe Docker Compose File The docker-compose file below (grabbed from here) involves using Traefik as the reverse proxy, but I should be able to customize for my use case, as I\u0026rsquo;m using NPM.\nversion: \u0026#39;3\u0026#39; services: vikunja: image: vikunja/vikunja environment: VIKUNJA_SERVICE_PUBLICURL: https://vikunja.jimsgarage.co.uk VIKUNJA_DATABASE_HOST: db:3306 VIKUNJA_DATABASE_PASSWORD: changeme VIKUNJA_DATABASE_TYPE: mysql VIKUNJA_DATABASE_USER: vikunja VIKUNJA_DATABASE_DATABASE: vikunja VIKUNJA_SERVICE_JWTSECRET: dskfj23kkjsdkjsdfjkl3sdfgfsdfhsdfkh3ozxpqzx volumes: - ./files:/app/vikunja/files networks: - proxy depends_on: db: condition: service_healthy restart: unless-stopped labels: - \u0026#34;traefik.enable=true\u0026#34; - \u0026#34;traefik.http.routers.vikunja.entrypoints=http\u0026#34; - \u0026#34;traefik.http.routers.vikunja.rule=Host(`vikunja.jimsgarage.co.uk`)\u0026#34; - \u0026#34;traefik.http.middlewares.vikunja-https-redirect.redirectscheme.scheme=https\u0026#34; - \u0026#34;traefik.http.routers.vikunja.middlewares=vikunja-https-redirect\u0026#34; - \u0026#34;traefik.http.routers.vikunja-secure.entrypoints=https\u0026#34; - \u0026#34;traefik.http.routers.vikunja-secure.rule=Host(`vikunja.jimsgarage.co.uk`)\u0026#34; - \u0026#34;traefik.http.routers.vikunja-secure.tls=true\u0026#34; - \u0026#34;traefik.http.routers.vikunja-secure.service=vikunja\u0026#34; - \u0026#34;traefik.http.routers.vikunja.tls.certResolver=cloudflare\u0026#34; - \u0026#34;traefik.http.services.vikunja.loadbalancer.server.port=3456\u0026#34; - \u0026#34;traefik.docker.network=proxy\u0026#34; db: image: mariadb:10 command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci environment: MYSQL_ROOT_PASSWORD: supersupersecret MYSQL_USER: vikunja MYSQL_PASSWORD: changeme MYSQL_DATABASE: vikunja networks: - proxy volumes: - ./db:/var/lib/mysql restart: unless-stopped healthcheck: test: [\u0026#34;CMD-SHELL\u0026#34;, \u0026#34;mysqladmin ping -h localhost -u vikunja --password=changeme\u0026#34;] interval: 2s start_period: 30s networks: proxy: external: true ","permalink":"https://deuts.org/p/vikunja-update-2024/","summary":"There seems to be a new update on Vikunja.","title":"Update on Vikunja"},{"content":"Insider Business shows 11 of the most faked foods in the world, which include:\nTruffles Maple Syrup Wasabi Parmesan Cheese Vanilla Caviar Honey Olive Oil Wagyu Beef Coffee Saffron \u0026nbsp; Of the 11, I would say fake parmesan cheese, honey and olive oil are the most I probably am guilty of consuming. I realize this now, I should be cautious when I\u0026rsquo;m doing my groceries next time.\n","permalink":"https://deuts.org/p/most-faked-food/","summary":"We need to be more vigilant the next time we do our groceries.","title":"11 Most Faked Foods In The World"},{"content":"I\u0026rsquo;ve recently seen these Youtube shorts that promote The Smoothie Diet. I\u0026rsquo;m sure the Youtube channel that uploads these videos (@Animememes1) is simply grabbing some weight transformation videos from Tiktok, upload them as Shorts in their Youtube channel, and adding a link in the comments about the Smoothie Diet.\nPlease don\u0026rsquo;t fall for this scam. These smoothies are so full of sugar, you don\u0026rsquo;t want them on your bodies. The real weight-loss strategy is totally free — you don\u0026rsquo;t have to pay a dime, you have nothing in advance to prepare: Intermittent Fasting.\nLook it up, especially about the power and benefits of the \u0026lsquo;clean\u0026rsquo; fast. And while you\u0026rsquo;re at it, you would help yourself better if you try and read Gin Stephen\u0026rsquo;s Fast, Feast, Repeat and Delay, Don\u0026rsquo;t Deny.\n","permalink":"https://deuts.org/p/the-smoothie-diet-scam/","summary":"Please, don\u0026rsquo;t fall for this scam. The real eating habit that\u0026rsquo;ll totally bring weight-loss and health benefits is Intermittent Fasting. Trust me.","title":"The Smoothie Diet Scam"},{"content":"I would really like to learn Python to reinforce my data analysis skills. And I would like to start with this 4-hour free course on Youtube.\nSharing this here if you want to join me as well.\n\u0026nbsp; ","permalink":"https://deuts.org/p/data-analysis-python-excel/","summary":"Let\u0026rsquo;s start learning Python with this 4-hour free course on Youtube.","title":"Data Analysis with Python for Excel Users"},{"content":"Vikunja is a powerful open-source todo app that provides users with a range of features designed to enhance productivity. It offers task tracking, due date management, collaboration tools, and more, all within an intuitive interface.\nInstalling via Vikunja via Docker, though, requires quite a number of containers running. The normal install alone needs a minimum 4 containers:\ndatabase api frontend nginx When I tried running them via docker-compose, I encountered a lot of this kind of Internal Server Error:\nAnd sometimes logging in returned repetitive API errors.\nI read somewhere that installing Redis along within the same docker-compose file helps. So I did.\nBut I still encountered several Internal Server Errors, albeit on rarer occasions this time.\n5 Docker Containers, and still errors. Vikunja left me no choice but to run:\ndocker-compose down docker image prune -a cd .. rm -R vikunja ","permalink":"https://deuts.org/p/vikunja-internal-server-error/","summary":"Even with all the fancy containers, I find it not reliable.","title":"I can't make Vikunja work on my set up"},{"content":"After installing Nextcloud via Docker, and if you go to /settings/admin/overview, you might find some warnings that you need to do further configurations to get rid of.\nService Discovery Your web server is not properly set up to resolve \u0026ldquo;/.well-known/caldav\u0026rdquo;. Your web server is not properly set up to resolve \u0026ldquo;/.well-known/carddav\u0026rdquo;.\nGo to the app/ directory where you\u0026rsquo;ll find the .htaccess file, and change the following lines:\nRewriteRule ^\\.well-known/carddav /remote.php/dav/ [R=301,L] RewriteRule ^\\.well-known/caldav /remote.php/dav/ [R=301,L] To:\nRewriteRule ^\\.well-known/carddav https://%{SERVER_NAME}/remote.php/dav/ [R=301,L] RewriteRule ^\\.well-known/caldav https://%{SERVER_NAME}/remote.php/dav/ [R=301,L] Source Cron Jobs not working You will need to setup a cron job from your host system. Try:\nsudo crontab -e Then add this line at the bottom:\n*/5 * * * * docker exec -u www-data [containername] php /var/www/html/cron.php Make sure to change [containername] to the actual name of your container.\nSource ","permalink":"https://deuts.org/p/nextcloud-post-install-config/","summary":"Get rid of several warnings in your Nextcloud admin dashboard.","title":"A few Nextcloud post-installation configurations"},{"content":"Update the system From this moment, we\u0026rsquo;ll assume you\u0026rsquo;re still logged in as root. After all, this is a fresh install of Linux, right?\napt update apt upgrade -y Install essential utilities apt install sudo htop curl nano wget net-tools Change root password This is just in case you don\u0026rsquo;t think the assigned root password is not complex enough for your liking:\npasswd Then enter you new password twice.\nUpdate Timezone dpkg-reconfigure tzdata Add non-root user Add user Change username with the username of your choice:\nadduser username Add user to sudoers group usermod -aG sudo username So, the non-root user is ready. From this moment on, we\u0026rsquo;ll assume you\u0026rsquo;re logged as that non-root user.\nChange the hostname Edit /etc/hostname sudo nano /etc/hostname And change accordingly.\nEdit /etc/hosts sudo nano /etc/hosts And change accordingly.\nReboot sudo reboot Install Docker and Docker Compose Install Docker Follow the instructions applicable for your system from the official Docker documentation. My favorite systems are Ubuntu and Debian, and I actually prefer to use the install using the repository method:\nSet up Docker\u0026rsquo;s Apt repository For Ubuntu # Add Docker\u0026#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update For Debian # Add Docker\u0026#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update Install the Docker packages sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Install Docker Compose sudo apt install docker-compose Add user to the Docker group Check if docker group already exists: grep docker /etc/group Add user to the docker group: usermod -aG docker username (don\u0026rsquo;t forget to change username to the username of your choice) Create a network bridge for Docker Containers From now on, the instructions here is if you plan to expose your applications via Cloudflare Tunnel.\ndocker network create -d bridge cloudflared Install Cloudflare Tunnel Make a directory: mkdir appdata/cloudflared (the directory structure is up to you) CD to that directory: cd appdata/cloudflared Create the docker-compose.yml file: nano docker-compose.yml Then paste the following:\nversion: \u0026#34;3.3\u0026#34; services: tunnel: container_name: cloudflared-tunnel image: cloudflare/cloudflared restart: unless-stopped command: tunnel --no-autoupdate run environment: - TUNNEL_TOKEN=[paste_here_your_actual_token] networks: - cloudflared networks: cloudflared: external: true Don\u0026rsquo;t forget to paste your actual token that will be generated when you create a new tunnel in Cloudflare.\nInstall Portainer Via Docker Compose Same as above, mkdir for portainer, then create the docker-compose.yml file:\nversion: \u0026#39;3\u0026#39; services: portainer: image: portainer/portainer-ce:latest container_name: portainer environment: - PUID=1000 - PGID=1000 - TZ=Asia/Manila restart: unless-stopped volumes: - /var/run/docker.sock:/var/run/docker.sock - ./data:/data # ports: # - 9000:9000 # - 8000:8000 # - 9443:9443 networks: - cloudflared networks: cloudflared: external: true Note that I commented out the ports portion of the docker-compose.yml because we\u0026rsquo;re not exposing the ports to the internet. Instead, we\u0026rsquo;re using Cloudflare Tunnel to expose the apps.\nInstall Duplicati All these efforts you do to set up Docker containers will go to waste if you don\u0026rsquo;t do a proper backup of your config and data files.\nversion: \u0026#34;2.1\u0026#34; services: duplicati: image: lscr.io/linuxserver/duplicati:latest container_name: duplicati environment: - PUID=0 - PGID=0 - TZ=America/Denver volumes: - ./config:/config - ./backups:/backups - /home/username:/source # ports: # - 8200:8200 restart: unless-stopped networks: - cloudflared networks: cloudflared: external: true I prefer to run Duplicati as root so I won\u0026rsquo;t have to deal with read permission issues in the future, so I set PUID and PGID to 0. Needless to say, you have to change your TZ and your source folder to map to the container.\n","permalink":"https://deuts.org/p/new-vps-checklist/","summary":"Got a new Ubuntu or Debian VPS server? Here are the things you should do to make the most out of it.","title":"Checklist of things to do on a new VPS server"},{"content":"Via APT If you\u0026rsquo;re running Debian or Ubuntu on your VPS, you can actually easily install Hugo via:\nsudo apt install hugo However, the version you can get from the repository is so old. Mine\u0026rsquo;s around version 0.80 I think.\nVia Deb file from Github Download and Run If you want the latest version of Hugo installed, you need to get it from github. As of this writing, the latest version is v0.117.0. Thus, you can run:\nwget https://github.com/gohugoio/hugo/releases/download/v0.117.0/hugo_extended_0.117.0_linux-amd64.deb sudo dpkg -i hugo_extended_0.117.0_linux-amd64.deb Copy the Hugo file By default, using the above method, hugo is saved under /usr/local/bin. You can verify that by running which hugo command. But this needs to be copied to the /usr/bin folder. Thus, run:\nsudo cp /usr/local/bin/hugo /usr/bin/ Check version You can double check if indeed you have the latest version by running:\nhugo version Updating Hugo to the latest release Redo all the installation instructions above including the sudo cp /usr/local/bin/hugo /usr/bin/ command.\n","permalink":"https://deuts.org/p/hugo-linux-vps/","summary":"Let me help you run Hugo on a Debian or Ubuntu Linux server.","title":"How to install Hugo in a Linux VPS"},{"content":"Quickly The easy approach is to use:\ndocker ps --size But this will output a long table with columns:\nContainer ID Image Command Created Status Ports Names Size Let\u0026rsquo;s refine the command More likely, you\u0026rsquo;re just curious about these columns:\nContainer ID Names Image Size In order to do so, just run:\ndocker ps -a --size --format \u0026#34;table {{.ID}}\\t{{.Names}}\\t{{.Image}}\\t{{.Size}}\u0026#34; Source ","permalink":"https://deuts.org/p/docker-container-size/","summary":"Which image occupies my VPS storage the most?","title":"Docker Command to Check the Sizes of your Containers"},{"content":"Have you ever encountered issues with legacy keyrings when running a fresh install of Debian or Ubuntu?\nW: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details\nThe Quick Fix cd /etc/apt sudo cp trusted.gpg trusted.gpg.d sudo apt update More info can be read here.\n","permalink":"https://deuts.org/p/key-legacy-trusted-gpg-keyring/","summary":"How to get rid of this deprecation error in Ubuntu or Debian?","title":"Key Is Stored in Legacy Trusted.gpg Keyring"},{"content":"What if:\nYou installed Nextcloud via Docker You created files or subfolders in the Nextcloud folder of a user This is also true if you\u0026rsquo;re restoring files and folders from a backup You can\u0026rsquo;t see the files or subfolders in the Nextcloud web interface Just run the following command, replacing nextcloud_app with the actual container name of your Nextcloud Docker install:\ndocker exec -u www-data nextcloud_app php occ files:scan --all This is working for me, on Nextcloud version 27.0.1.\n","permalink":"https://deuts.org/p/how-to-rescan-docker-nextcloud-folders/","summary":"Wait, where did my files go?","title":"How to Rescan Your Docker Nextcloud Folders"},{"content":"This article promises I would enjoy Andor. I should probably start watching these Star Wars TV shows.\nHow come every time I come here to just post a quick short post, I end up with a long one?\nExcel is dead? What a stupid question. This guy doesn\u0026rsquo;t use Microsoft Excel as much as I do. Such a click-bait.\nYugatech: Disney+ coming to the Philippines on November 17. Price starts at P159 for mobile plan and P369 for premium. Take your pick: you split the subscription price, or just do everything, every streaming service, on Plex.\nA bridge collapsed in Bayambang, Pangasinan. That\u0026rsquo;s why it\u0026rsquo;s so scary to be stuck in traffic while in the middle of a bridge.\nThe Underrated TV Shows in 2022 I think these are the shows you shouldn\u0026rsquo;t miss in 2022:\nWeCrashed Slow Horse The Dropout Severance Winning Time: The Rise of the Lakers Dynasty Blackbird Of course, the House of the Dragon is not mentioned in this list, because it belongs to a totally different list.\nLegacy: The True Story of the LA Lakers This TV series is so full of rich stories about the story behind the LA Lakers upon the ascension of Jerry Buss to the head of the organization. But it\u0026rsquo;s also full of interviews, and less drama actually.\n","permalink":"https://deuts.org/p/underrated-tv-shows-2022-et-al/","summary":"Start watching them the soonest you can!","title":"The Underrated TV Shows of 2022 Et Al"},{"content":"There are times that you you want to use the Table.Skip Power Query function, but the number of rows you want to skip varies from file to file in your folder. You want the number of rows to be dynamic.\nThe function below will count the number of rows under the column Column4 while the rows are nulls.\nTable.Skip(Source, each [Column4] = null) Watch the video.\n","permalink":"https://deuts.org/p/power-query-table-skip-while-row-is-blank/","summary":"Use the Table.Skip function the dynamic way.","title":"Power Query Table.Skip While Row Is Blank"},{"content":"With all the hype about ChatGPT nowadays, I really have to try it. And I\u0026rsquo;m still wondering how to install Mastodon on Debian 11 without Docker. And here\u0026rsquo;s the AI\u0026rsquo;s response:\nHow to Install Mastodon on Debian 11 Without Docker (instructions generated from ChatGPT) To install Mastodon, the open-source, decentralized social networking platform, on Debian 11 without using Docker, you can follow these steps:\nFirst, make sure you have the necessary dependencies installed on your system. This includes PostgreSQL, Redis, and Yarn. You can install these using the following commands: sudo apt-get update sudo apt-get install postgresql postgresql-contrib sudo apt-get install redis-server curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo \u0026#34;deb https://dl.yarnpkg.com/debian/ stable main\u0026#34; | sudo tee /etc/apt/sources.list.d/yarn.list sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install yarn Next, clone the Mastodon Git repository to your local machine using the following command: git clone https://github.com/tootsuite/mastodon.git Navigate to the Mastodon directory and install the necessary dependencies using Yarn: cd mastodon yarn install Next, you will need to configure Mastodon by copying the .env.production.sample file to .env.production and editing it to set the appropriate values for your environment. This includes setting up your database, caching, and other options.\nOnce the configuration is complete, you can compile the Mastodon assets using the following command:\nRAILS_ENV=production bundle exec rails assets:precompile Finally, you can start the Mastodon server using the following command: RAILS_ENV=production bundle exec rails s Mastodon should now be running on your system. You can access it in your web browser at http://localhost:3000.\nNote: The steps outlined above are a simplified version of the installation instructions for Mastodon. For more detailed instructions and additional options, please refer to the Mastodon documentation.\nI still have to try this And I still have to try this soon. Will provide feedback if this instuction prove helpful.\n","permalink":"https://deuts.org/p/install-mastodon-debian-11-without-docker/","summary":"This is how ChatGPT would install Mastodon on a bare metal VPS.","title":"How to Install Mastodon on Debian 11 Without Docker"},{"content":"Abrar Al-Heeti over at CNET discusses why she\u0026rsquo;s now Team Apple and never going back.\nIf I were to summarize her reasoning for doing so, the major reason is iMessage and Airdrop. The rest are just aesthetics.\niMessage I don\u0026rsquo;t have an iPhone right now, but who texts nowadays anyway? If you look closely at my messages app, they\u0026rsquo;re mostly made up of OTPs and marketing messages. Not much from real contacts.\nWhere I\u0026rsquo;m from and where I work, messaging is usually done via Viber and Facebook Messenger. So I\u0026rsquo;ll just say damn to those who insist on iMessage.\nMoreover, I think the Android messages app has a more robust anti-spam capability than the iPhone. By the way, did you know that you can\u0026rsquo;t change the default SMS app in the iPhone?\nAirdrop Who needs original quality photos? They\u0026rsquo;re big in file size and you\u0026rsquo;re not printing them into billboards anyway. And if you really need it, there are alternatives other than Google Drive.\nIndispensable on my Android Dual Sim Yes, there are dual-sim and e-Sim capable iPhones but you have to be very special to use one especially in the Philippines. Globe and Smart can only activate your e-Sim if you\u0026rsquo;re on a postpaid plan. You\u0026rsquo;ll need to procure yours from HongKong if you want a dual-sim iPhone. Almost every Android phone has dual-sim capability.\nTorrenting apps I don\u0026rsquo;t use my uTorrent app too often on my Android phone as I have a Qbittorrent hosted on a VPS, but I\u0026rsquo;m glad that it\u0026rsquo;s there when I need it.\nSyncthing Not on an iPhone. Period.\nUSB Type-C This may change soon, but I\u0026rsquo;m leaving it here anyway. I can carry around with me just one charger for my laptop, tablet and smartphone.\nCustomizable Home Screen This feature may become a time-waster sometimes, even a resource-hog, but the fact that I can move around app icons even to the bottom of the screen offers a lot of flexibility on how I want my phone to look each time I unlock it.\nIf you\u0026rsquo;re not too convinced, check out r/NovaLauncher and r/NiagaraLauncher for inspiration.\nExpandable Storage This feature probably becomes less attractive as built-in storage options become larger, but I\u0026rsquo;m still attracted to this option, and plays a role in my decision to stick to Android, at least for the foreseeable future.\nDual Accounts/Profile I know apps like Facebook and Messenger have the capability to run multiple profiles in the same app, but I don\u0026rsquo;t think you can get notifications for them all.\nWith features like in the Samsung\u0026rsquo;s secret folder, you can essentially have two separate Viber accounts for example running, and you\u0026rsquo;ll get notifications from both accounts.\n","permalink":"https://deuts.org/p/iphone-vs-android/","summary":"One of those posts explaining why an Android device is better than the iPhone.","title":"Yet another iPhone vs. Android post"},{"content":" Bitcoin isn\u0026rsquo;t really used much as a currency at all.\nWhen people buy bitcoin, they rarely use it to buy goods and services. They\u0026rsquo;re really buying access to a Ponzi scheme.\n\u0026nbsp; I subscribe to this school of thought. Bitcoin is probably a good idea as a currency. Problem is, people don\u0026rsquo;t exchange their dollars for Bitcoin and use it to buy goods and services. Instead, they buy it in the hopes that other people will hop on the bandwagon, and cash-in on its price appreciation.\nThe same thing applies to other Cryptocurrencies.\n","permalink":"https://deuts.org/p/why-bitcoin-is-a-scam/","summary":"No intrinsic value, it\u0026rsquo;s a scam!","title":"Why Bitcoin Is a Scam"},{"content":"I was wondering why Docker apps don\u0026rsquo;t come as easy to install like Linuxserver\u0026rsquo;s? Case in point: Joplin.\nWell, I really do think Joplin server\u0026rsquo;s documentation needs a lot more polishing. Fortunately I was able to make it work in my system, even without exposing additional ports to the public, which I\u0026rsquo;m sharing below.\nWhy Joplin Server instead of Webdav, Dropbox, OneDrive, NextCloud, etc. According to Noted:\nSpeed up the sync\nI still have to find out if this really is true Sharing a note with anyone, using a URL\nThis is actually my favorite feature. This enables me to share notes that are not so private to other people by just sharing a link to the public page. Then as I update my note, the page also updates. User access\nI still have to evangelize other people about Joplin so I could add users to my Joplin server, if ever they need a sync server. Sharing a notebook with a user on the same Joplin Server\nThis is also a great feature, especially if I have other users I can share my Joplin server with. Docker Compose for Joplin Server Docker Network Make sure that you already have a ready Docker Network for your Joplin app and database. This will make sure that you don\u0026rsquo;t expose additional ports to the public. If you don\u0026rsquo;t have a dedicated network yet, just run:\nsudo docker network create -d bridge examplenetwork Nginx Proxy Manager I would assume that you already have the Nginx Proxy Manager installed and it\u0026rsquo;s running in the same examplenetwork . Now, add a new Proxy Host with your domain name, e.g. joplin.example.com, then hostname should be joplin_app (container name below) and port 22300.\nInstall Joplin App and DB On your favorite directory, just create the docker-compose.yml file, which should contain:\nversion: \u0026#39;3\u0026#39; services: db: image: postgres:13 container_name: joplin_db volumes: - ./data/postgres:/var/lib/postgresql/data # ports:\twe don\u0026#39;t need this anymore because we\u0026#39;re reverse proxying anyway # - \u0026#34;5432:5432\u0026#34; restart: unless-stopped environment: - POSTGRES_PASSWORD=yHZ4TbsyKJI0Xi2sUmXDuz - POSTGRES_USER=Barrier1542 - POSTGRES_DB=Sudden9997 networks: - examplenetwork app: image: joplin/server:latest depends_on: - db container_name: joplin_app # ports:\twe don\u0026#39;t need this anymore because we\u0026#39;re reverse proxying anyway # - \u0026#34;22300:22300\u0026#34; restart: unless-stopped environment: - APP_PORT=22300 - APP_BASE_URL=https://joplin.example.com - DB_CLIENT=pg - POSTGRES_PASSWORD=yHZ4TbsyKJI0Xi2sUmXDuz - POSTGRES_DATABASE=Sudden9997 - POSTGRES_USER=Barrier1542 - POSTGRES_PORT=5432 - POSTGRES_HOST=db networks: - examplenetwork networks: examplenetwork: external: true Don\u0026rsquo;t worry about the usernames and passwords in my sample docker-compose.yml file, they were just randomly generated and not used for production elsewhere.\nThen run sudo docker-compose up -d\nDid you know that the Joplin docker image alone is worth 1.2GB of storage in your server? Postgres is another 373MB.\nBackup with Duplicati As Joplin populates your /data/postgres folder in the initial setup, as well as along the way as you actually use your server, it creates files and directories with user and group permissions assigned to systemd-coredump. Worse, they are readable and writable by the user only. That is usually fine, until you try backing them up using Duplicati.\nThe solution: run your Duplicati docker app with root privileges.\nI know the rule about not running apps as root. But that\u0026rsquo;s the only way I see so far that work. Perhaps, Joplin could give us an option to create and update files in the persistent volumes as a regular user. That way, I can run Duplicati as that same user and could access the files for backup.\nUpdate as of Mar. 24, 2024 For whatever reason, recently I noticed my Joplin server was down. The GUI is not accessible, and the sync process is not pushing though. Looked at the log, and it appears the Joplin app container is having trouble connecting to the Postgres database.\nIn order to fix it, I needed to remove all the reference to the examplenetwork and uncomment all ports to make them active. Moreover, I needed to point directly the hostname in Nginx Proxy Manager (NPM) to the server\u0026rsquo;s IP address.\nversion: \u0026#39;3\u0026#39; services: db: image: postgres:13 container_name: joplin_db volumes: - ./data/postgres:/var/lib/postgresql/data ports: - \u0026#34;5432:5432\u0026#34; restart: unless-stopped environment: - POSTGRES_PASSWORD=yHZ4TbsyKJI0Xi2sUmXDuz - POSTGRES_USER=Barrier1542 - POSTGRES_DB=Sudden9997 app: image: joplin/server:latest depends_on: - db container_name: joplin_app ports: - \u0026#34;22300:22300\u0026#34; restart: unless-stopped environment: - APP_PORT=22300 - APP_BASE_URL=https://joplin.example.com - DB_CLIENT=pg - POSTGRES_PASSWORD=yHZ4TbsyKJI0Xi2sUmXDuz - POSTGRES_DATABASE=Sudden9997 - POSTGRES_USER=Barrier1542 - POSTGRES_PORT=5432 - POSTGRES_HOST=db ","permalink":"https://deuts.org/p/joplin-npm-duplicati-docker/","summary":"The ultimate way to install the Joplin server while using NPM and Docker.","title":"Make Joplin work with Nginx Proxy Manager and Duplicati (Docker)"},{"content":"When I started hoarding movies and TV shows back when streaming services were not yet a thing, of course I played them using VLC. But you can only do that on a computer. These media are better consumed over TV, right?\nThen, the rise of Netflix showed us a glipmse of how your media should be better managed — with posters or thumbnails, description or summary, genre, casts list, and even related movies to watch after. I remember I used to have several hard drives with duplicate movies from several sources or several different versions and video codecs. Worse, it was so hard to keep track back then which movies you\u0026rsquo;ve already watched or what episode of a show did you last watch.\nThen came Kodi. And you can sync your collection and watch status with Trakt. But Kodi was supposed to manage your local files only — or so I knew.\nIf you have a VPS or even a local server with your media files while running Apache or Nginx to serve webpages and/or files, you can actually add those folders as a media source to your Kodi app. The video below will show you how:\n\u0026nbsp; Of course, now there are media servers like Plex, Emby and Jellyfin to help you manage and stream your media files. But Kodi has a lot to offer over these other apps, and that\u0026rsquo;s a totally different topic.\nFAQ Will this work with HTTP Basic Authentication on Nginx server? I actually have yet to try this out, and will update this post when I find out. But feel free to mention me @deuts if you know the answer.\n","permalink":"https://deuts.org/p/streaming-movies-tv-shows-kodi/","summary":"This may not work currently on my setup, but leaving it here anyway.","title":"Streaming Movies and TV Shows on Kodi"},{"content":"These are the TV shows that I deleted from my Sonarr installation, but may consider following or monitoring them in the future.\nBad Sisters Gaslit Hacks Mindhunter The Morning Show Only Murders in the Building Season 2 Severance Season 2 Slow Horses Season 2 The Time Traveler\u0026rsquo;s Wife Warrior What We Do in the Shadows Several of these I have watched the Season 1 already, and will definitely add them back when Season 2 are ready.\n","permalink":"https://deuts.org/p/tv-shows-consider-watching-future/","summary":"The must see shows in the future according to DeutsFlix.","title":"TV Shows I May Consider Watching in the Future"},{"content":"Ran my 3 websites on GT Metrix, and this is what I got:\nCurrent, they are running on the following platforms:\nWebsite Platform deuts.org Hugo deuts.net WordPress chesshive.com WordPress That goes to show how efficient static site generators like Hugo can be to make your websites more user and search friendly.\n","permalink":"https://deuts.org/p/gt-metrix-comparison-3-websites/","summary":"A Hugo site, being all just HTML files, can really be that fast.","title":"GT Metrix Comparison of my 3 Websites"},{"content":" \u0026nbsp; I don\u0026rsquo;t think they are comparable. Notion is for note-taking app/service while Airtable is for databases and workflow. You may also build databases in Notion but it\u0026rsquo;s quite limited in functionality. And Airtable has robust API that you can interact with using Excel.\n","permalink":"https://deuts.org/p/notion-vs-airtable/","summary":"Airtable for the win!","title":"Notion vs Airtable"},{"content":"Bumped into this post on Reddit, asking if his \u0026lsquo;old\u0026rsquo; laptop can handle Plex:\nImagine: a 7th-gen i5 with a dedicated NVIDIA graphics, and he\u0026rsquo;s asking if his laptop can handle Plex. I\u0026rsquo;m sure this spec can handle 1 or 2 4K streams easily.\nI have an old Beelink S1 Mini PC, with an Intel Celeron N3450, Quad Core, 4GB of RAM and 64GB eMMC, and this thing handles Plex well, albeit I only watch 720p movies and shows. But it\u0026rsquo;s running not just Plex, but a host of other docker containers, including but not limited to:\nRadarr Sonarr Nginx Proxy Manager WordPress server and database Tautulli Portainer Syncthing Duplicati Jackett NZBGet Dockuwiki ruTorrent So, yeah, to answer OP\u0026rsquo;s question, it is very much capable.\n","permalink":"https://deuts.org/p/can-old-laptop-handle-plex/","summary":"An Intel 7th Gen i5 is more than enough to run Plex.","title":"Can This Old Laptop Handle Plex?"},{"content":"Long commands are hard to memorize Let\u0026rsquo;s say for example you want to run hugo server, but instead of on the localhost you want to run it over your VPS server (or even from your home server). Without the bash script, you\u0026rsquo;ll need to run:\nhugo server --bind=\u0026lt;IP ADDRESS\u0026gt; --baseURL=http://\u0026lt;IP ADDRESS\u0026gt;:1313 Create a bash script Create the bash file Let\u0026rsquo;s name the bash file serve.sh\nnano serve.sh Enter your commands #!/bin/bash hugo server --bind=\u0026lt;IP ADDRESS\u0026gt; --baseURL=http://\u0026lt;IP ADDRESS\u0026gt;:1313 Don\u0026rsquo;t forget to include #!/bin/bash at the first line.\nMultiple Commands If you need to make multiple commands, enter each command in separate lines, and end the file with exec bash, like for example:\n#!/bin/bash cd appdata/app/subfolder PS1=\u0026#39;$(whoami)@$(hostname):$(pwd)# \u0026#39; exec bash Ctrl+O to save the file\nCtrl+X to close the file\nMake it executable sudo chmod +x serve.sh Enter password as may be necessary.\nRun the script ./serve.sh Assuming we don\u0026rsquo;t get into permission problems, our script should be working well.\n","permalink":"https://deuts.org/p/create-bash-script-executable/","summary":"Put long commands in a bash script so you don\u0026rsquo;t have to remember them.","title":"How to Create a Bash Script and Make it Executable?"},{"content":" Ano ang nasa dakong paroon,\nbunga ng malilikot na pagiisip,\nlikha ng balintataw o halaw\nmula sa daigdig ng kababalaghan\ndi kayang ipaliwanag\nngunit alam mong magaganap\naawooooo!\n","permalink":"https://deuts.org/p/ano-ang-nasa-dakong-paroon/","summary":"Bunga ng malilikot na pag-iisip.","title":"Ano Ang Nasa Dakong Paroon"},{"content":"Price Increase Announcement Got an email today about the forthcoming price increase from Contabo. Also saw the discussion on Lowendtalk.\nWhat I use it for? Currently, I have my Plex server, Radarr, Sonarr, Qbittorrent, Bazarr, Tautulli, among others, installed on my Contabo servers. Beginning November 1, it appears my fee will increase from EUR4.99 to EUR5.99 per month. I know it\u0026rsquo;s not too much, especially for a 400GB SSD storage, 4-core CPU and 8GB RAM VPS server. It\u0026rsquo;s pretty much like paying for a Netflix subscription, but with so much more flexibility.\nBlack Friday Sale Black Friday is fast approaching. I\u0026rsquo;ll check out the Lowendbox and Lowendtalk sites for attractive sale that may fit my needs. Until then, I\u0026rsquo;ll keep my Contabo server.\n","permalink":"https://deuts.org/p/contabo-price-increase-2022/","summary":"It\u0026rsquo;s not worth it, I promise you!","title":"Contabo Price Increase 2022"},{"content":"This video runs you through the interface of basketball video games way back to 1974. To me, it brings back not really a lot of memories, but particular memories, like the Double Dribble of the Family Computer days and the NBA Live 2004 of office tournaments via LAN days.\n\u0026nbsp; ","permalink":"https://deuts.org/p/basketball-video-games-evolution/","summary":"Look at how the graphics improved over the years.","title":"Basketball Video Games Evolution"},{"content":"Don\u0026rsquo;t you find this outlook from BPI a little too agressive for your taste? And they call it \u0026lsquo;Base Case Scenario\u0026rsquo;.\nUSD/PHP Quarterly Outlook 4Q-2022 to FY 2023 Forecast (end of period) Base Scenario 4Q 2022 58.100 1Q 2023 58.705 2Q 2023 59.311 3Q 2023 59.916 4Q 2023 60.521 ","permalink":"https://deuts.org/p/bpi-usd-php-outlook-2023/","summary":"The unattainable forecasts.","title":"BPI USD/PHP Outlook 2023"},{"content":"Here\u0026rsquo;s a detailed tutorial on how to setup and run Oracle Cloud Free Tier.\n\u0026nbsp; Ain\u0026rsquo;t this too good to be true. Two things you have to be wary about:\nIt\u0026rsquo;s from Oracle, depends on you if you trust that name. But I worry how long will it remain free. It\u0026rsquo;s running on ARM, so your favorite docker app might not be compatible. Out of Capacity So I tried sigining up for Oracle Free Tier VM instance, and of course I bumped into the dreaded \u0026lsquo;Out of capacity for shape \u0026hellip; in availability domain \u0026hellip;\u0026rsquo;\nIndeed, too good to be true!\n","permalink":"https://deuts.org/p/oracle-cloud-free-tier/","summary":"A guide to using Oracle Cloud Free Tier—just a heads-up: Oracle’s reliability can be hit-or-miss, Docker may have ARM compatibility issues, and I encountered an \u0026ldquo;Out of capacity\u0026rdquo; error at signup.","title":"Oracle Cloud Free Tier"},{"content":" \u0026nbsp; This is exactly what brave men should say:\nIf you tell me I\u0026rsquo;m wrong\nI don\u0026rsquo;t wanna be right\n","permalink":"https://deuts.org/p/nico-vinz-am-i-wrong/","summary":"Dedicated to all the brave men out there.","title":"Nico \u0026 Vinz - Am I Wrong"},{"content":"I wonder how I\u0026rsquo;ve come to know this function just now. I have so much use for the STOCKHISTORY function to manage my personal stock portfolio.\n\u0026nbsp; ","permalink":"https://deuts.org/p/excel-stockhistory-function-pro-tips/","summary":"The first time I learned about \u0026lsquo;STOCKHISTORY\u0026rsquo; function.","title":"Excel Stockhistory Function Pro Tips"},{"content":"I really want to try this at home. They\u0026rsquo;re so expensive to order outside, now I want unli beef recipes on my table.\n\u0026nbsp; Recipes include:\nGarlic Pepper Beef (Filipino) Bulgogi (Korean) Pepper Beef (ala Pepper Lunch) (Japanese) What are the other better Bulgogi ingredients I can try?\n","permalink":"https://deuts.org/p/beef-fast-food-recipes/","summary":"Get ready to grill! Your kitchen\u0026rsquo;s about to go full Bulgogi bonanza—hope you\u0026rsquo;re prepared to raise the steaks on flavor!","title":"Beef Fast Food Recipes"},{"content":" History does not remember blood.\nIt remembers names.\n— Corlys Velaryon\n","permalink":"https://deuts.org/p/blood-vs-name/","summary":"A powerful reminder that what we leave behind is often more about our legacy and reputation than the battles we\u0026rsquo;ve fought.","title":"Blood vs. Name"}]